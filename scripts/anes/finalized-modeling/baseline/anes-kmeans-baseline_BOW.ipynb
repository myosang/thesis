{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1846dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b916b",
   "metadata": {},
   "source": [
    "Call the dataframe that contains the processed text data including stopwords removal, lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898971f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset of stacked responses\n",
    "mstack = pd.read_json(\"~/thesis/data/processed_uscensus/political_mentions_stack.jsonl\", orient = \"records\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf857af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset of each responses\n",
    "m1 = pd.read_json(\"~/thesis/data/processed_uscensus/political_mention1.jsonl\", orient = \"index\")\n",
    "m2 = pd.read_json(\"~/thesis/data/processed_uscensus/political_mention2.jsonl\", orient = \"index\")\n",
    "m3 = pd.read_json(\"~/thesis/data/processed_uscensus/political_mention3.jsonl\", orient = \"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d88827",
   "metadata": {},
   "source": [
    "## Participant-based analysis\n",
    "### 1. Dataset: concatenated texts from the mention 1,2,3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9408166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mconcat = pd.read_json(\"~/thesis/data/processed_uscensus/political_mentions.jsonl\", orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee636d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200015</th>\n",
       "      <td>racim blacks whites false information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200022</th>\n",
       "      <td>coming together country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200039</th>\n",
       "      <td>severe political polarization allow compromise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200046</th>\n",
       "      <td>pandemic covid 19 unemployment lot people loss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200053</th>\n",
       "      <td>globalism fake covid law order blm public educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535315</th>\n",
       "      <td>unity people harming coming together one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535360</th>\n",
       "      <td>divisiveness divided unified race inequality p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535414</th>\n",
       "      <td>health immigration way separate families globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535421</th>\n",
       "      <td>bias main stream media border control illegal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535469</th>\n",
       "      <td>pandemic totally control equapilty issue racia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7298 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mentions\n",
       "200015            racim blacks whites false information  \n",
       "200022                          coming together country  \n",
       "200039  severe political polarization allow compromise...\n",
       "200046  pandemic covid 19 unemployment lot people loss...\n",
       "200053  globalism fake covid law order blm public educ...\n",
       "...                                                   ...\n",
       "535315         unity people harming coming together one  \n",
       "535360  divisiveness divided unified race inequality p...\n",
       "535414  health immigration way separate families globa...\n",
       "535421  bias main stream media border control illegal ...\n",
       "535469  pandemic totally control equapilty issue racia...\n",
       "\n",
       "[7298 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1250f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = mconcat['mentions'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9679fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '04' ... 'zilch' 'zombie' 'zone']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Bag of Words model\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array to see the result\n",
    "X_array = X.toarray()\n",
    "\n",
    "# Feature names (words)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(features)\n",
    "print(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb511b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply KMeans clustering\n",
    "n_clusters = 2  # Example: trying to find 3 clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(X_array)\n",
    "\n",
    "# Get cluster labels\n",
    "labels = kmeans.labels_\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5c958f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.3205426774109418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate the silhouette score\n",
    "sil_score = silhouette_score(X_array, labels)\n",
    "print(f\"Silhouette Score: {sil_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67d3c5",
   "metadata": {},
   "source": [
    "**Result:** worse than the k-means distilbert responses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d7a26",
   "metadata": {},
   "source": [
    "### 2. Topics-dataset: stacked responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ba3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstack = pd.read_json(\"~/thesis/data/processed_uscensus/political_mentions_stack.jsonl\", orient = 'records', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "267e90ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>racim blacks whites false information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coming together country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>severe political polarization allow compromise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pandemic covid 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>globalism fake covid law order blm public educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16510</th>\n",
       "      <td>immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16511</th>\n",
       "      <td>pandemic people wanting comply mask mandate ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16512</th>\n",
       "      <td>global position us along around world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16513</th>\n",
       "      <td>attempt take away 2nd ammendment rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16514</th>\n",
       "      <td>gun control believe country needs move living ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16515 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   stack\n",
       "0                  racim blacks whites false information\n",
       "1                                coming together country\n",
       "2      severe political polarization allow compromise...\n",
       "3                                      pandemic covid 19\n",
       "4      globalism fake covid law order blm public educ...\n",
       "...                                                  ...\n",
       "16510                                        immigration\n",
       "16511  pandemic people wanting comply mask mandate ma...\n",
       "16512              global position us along around world\n",
       "16513            attempt take away 2nd ammendment rights\n",
       "16514  gun control believe country needs move living ...\n",
       "\n",
       "[16515 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63521a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = mstack['stack'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bec57f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '04' ... 'zilch' 'zombie' 'zone']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Bag of Words model\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array to see the result\n",
    "X_array = X.toarray()\n",
    "\n",
    "# Feature names (words)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(features)\n",
    "print(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96f29e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply KMeans clustering\n",
    "n_clusters = 4  # Example: trying to find 2 clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(X_array)\n",
    "\n",
    "# Get cluster labels\n",
    "labels = kmeans.labels_\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "665155be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.035337722201187714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate the silhouette score\n",
    "sil_score = silhouette_score(X_array, labels)\n",
    "print(f\"Silhouette Score: {sil_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ea5ff",
   "metadata": {},
   "source": [
    "**Result:** worse than the distilbert-kmeans result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2052b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kim - 1st Custom Python environment",
   "language": "python",
   "name": "my-python-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
