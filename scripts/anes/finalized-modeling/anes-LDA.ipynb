{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19f5f6b",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deef353c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49e2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import pickle\n",
    "import os\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46911cfc",
   "metadata": {},
   "source": [
    "## Participant-based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39ca2be",
   "metadata": {},
   "source": [
    "### 1.  Dataset: Create the BOW vector from the concatenated strings\n",
    "### * with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3c4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore, CoherenceModel\n",
    "\n",
    "# Load and concatenate the DataFrames\n",
    "def load_and_prepare_data(file_list):\n",
    "    dfs = [pd.read_json(file, orient='index') for file in file_list]\n",
    "    df = pd.concat(dfs, axis=1).fillna('')\n",
    "    df.columns = ['response1', 'response2', 'response3']\n",
    "    return df\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess(df):\n",
    "    combined_texts = df.apply(lambda row: ' '.join(row), axis=1)\n",
    "    texts = combined_texts.str.split().tolist()\n",
    "    return texts, combined_texts\n",
    "\n",
    "# Train LDA model\n",
    "def train_lda(corpus, dictionary, num_topics=5, random_state=42):\n",
    "    lda_model = LdaMulticore(\n",
    "        corpus=corpus, \n",
    "        id2word=dictionary, \n",
    "        num_topics=num_topics, \n",
    "        passes=10, \n",
    "        workers=4, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    return lda_model\n",
    "\n",
    "# Compute coherence score\n",
    "def compute_coherence(lda_model, texts, dictionary):\n",
    "    cm = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    return cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7083999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File list\n",
    "files = [\n",
    "    '/Users/gytkd/Desktop/Backup-Thesis/data/processed_uscensus/political_mention1.jsonl',\n",
    "    '/Users/gytkd/Desktop/Backup-Thesis/data/processed_uscensus/political_mention2.jsonl',\n",
    "    '/Users/gytkd/Desktop/Backup-Thesis/data/processed_uscensus/political_mention3.jsonl'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d299da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main process\n",
    "df = load_and_prepare_data(files)\n",
    "texts, combined_texts = preprocess(df)\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb3dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.copy()\n",
    "\n",
    "index_save = final_df.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ccb748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to determine the best number of topics\n",
    "num_topics_range = range(2, 11)  # Example range of topic numbers to try\n",
    "coherence_scores = []\n",
    "random_state = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc34685",
   "metadata": {},
   "source": [
    "### LDA model run below: untoggle the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f720c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_topics in num_topics_range:\n",
    "#     lda_model = train_lda(corpus, dictionary, num_topics=num_topics, random_state=random_state)\n",
    "#     coherence_lda = compute_coherence(lda_model, texts, dictionary)\n",
    "#     coherence_scores.append((num_topics, coherence_lda))\n",
    "#     lda_model.save(f'lda_multicore_model_{num_topics}')  # Save model per topic number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6cc8f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Print coherence scores for each number of topics\n",
    "# for num_topics, coherence_lda in coherence_scores:\n",
    "#     print(f'Num Topics: {num_topics}, Coherence Score: {coherence_lda}')\n",
    "\n",
    "# # Find the best number of topics\n",
    "# best_num_topics, best_coherence_lda = max(coherence_scores, key=lambda item: item[1])\n",
    "# print(f'Best Num Topics: {best_num_topics}, Best Coherence Score: {best_coherence_lda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033a45d",
   "metadata": {},
   "source": [
    "### reload the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b0c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num_topics = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc33e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the best model\n",
    "best_model_filepath = f'lda_multicore_model_{best_num_topics}'\n",
    "best_lda_model = LdaMulticore.load(best_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b129fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1782955774413442854649408\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1782955774413442854649408_data = {\"mdsDat\": {\"x\": [-0.05460036008268339, -0.03676287047687336, 0.09136323055955677], \"y\": [0.04887085434585415, -0.05567456841636479, 0.0068037140705106336], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [38.85430141065544, 36.19009116086519, 24.95560742847937]}, \"tinfo\": {\"Term\": [\"health\", \"racism\", \"climate\", \"need\", \"change\", \"people\", \"care\", \"police\", \"19\", \"covid\", \"lack\", \"inequality\", \"brutality\", \"get\", \"healthcare\", \"help\", \"coronavirus\", \"la\", \"racial\", \"race\", \"economic\", \"relations\", \"warming\", \"systemic\", \"affordable\", \"access\", \"poverty\", \"back\", \"education\", \"equality\", \"bottom\", \"package\", \"offended\", \"owners\", \"meet\", \"let\", \"expense\", \"sustainability\", \"jerrymandering\", \"tired\", \"paycheck\", \"owned\", \"legally\", \"cancer\", \"sometimes\", \"kill\", \"worrying\", \"proverty\", \"punishment\", \"road\", \"safely\", \"phones\", \"junk\", \"betterment\", \"examples\", \"leaves\", \"affiliation\", \"million\", \"hating\", \"zero\", \"warming\", \"help\", \"told\", \"need\", \"afford\", \"global\", \"checks\", \"back\", \"get\", \"talk\", \"raise\", \"decent\", \"people\", \"able\", \"living\", \"vote\", \"would\", \"spend\", \"improve\", \"want\", \"better\", \"dont\", \"working\", \"getting\", \"work\", \"come\", \"make\", \"needs\", \"money\", \"seem\", \"find\", \"voter\", \"something\", \"see\", \"one\", \"class\", \"environment\", \"pay\", \"together\", \"think\", \"many\", \"gun\", \"problems\", \"trump\", \"economy\", \"country\", \"party\", \"covid\", \"pandemic\", \"control\", \"jobs\", \"government\", \"healthcare\", \"much\", \"racism\", \"social\", \"political\", \"media\", \"problem\", \"19\", \"closing\", \"recession\", \"isnt\", \"limits\", \"slowly\", \"twitter\", \"losses\", \"proud\", \"communism\", \"trend\", \"eyes\", \"fallout\", \"discussion\", \"joe\", \"wins\", \"honestly\", \"closures\", \"compass\", \"militia\", \"downturn\", \"teacher\", \"hypocrisy\", \"tried\", \"ruin\", \"donations\", \"steal\", \"republic\", \"boys\", \"cultures\", \"overwhelming\", \"shutting\", \"biden\", \"term\", \"19\", \"left\", \"lose\", \"decline\", \"infection\", \"affecting\", \"covid\", \"virus\", \"rate\", \"due\", \"unemployment\", \"handled\", \"socialism\", \"corona\", \"issue\", \"problem\", \"immigration\", \"economy\", \"become\", \"elected\", \"life\", \"businesses\", \"socialist\", \"illegal\", \"pandemic\", \"country\", \"right\", \"election\", \"political\", \"media\", \"debt\", \"going\", \"us\", \"division\", \"government\", \"jobs\", \"people\", \"trump\", \"control\", \"much\", \"president\", \"lack\", \"many\", \"national\", \"police\", \"racism\", \"think\", \"la\", \"para\", \"pandemia\", \"inequalities\", \"que\", \"por\", \"es\", \"gaps\", \"de\", \"las\", \"pero\", \"personas\", \"hardship\", \"muy\", \"availability\", \"falta\", \"mas\", \"marginalized\", \"crises\", \"na\", \"los\", \"epa\", \"hay\", \"affordability\", \"billionaires\", \"el\", \"desempleo\", \"del\", \"gente\", \"prescription\", \"economia\", \"lgbtq\", \"systematic\", \"este\", \"brutality\", \"access\", \"health\", \"climate\", \"change\", \"affordable\", \"equality\", \"care\", \"police\", \"relations\", \"racism\", \"inequality\", \"coronavirus\", \"gender\", \"injustice\", \"lack\", \"systemic\", \"among\", \"insurance\", \"race\", \"gap\", \"poverty\", \"healthcare\", \"economic\", \"wealth\", \"racial\", \"education\", \"social\", \"country\", \"covid\", \"pandemic\", \"poor\", \"rights\", \"issues\", \"income\", \"division\", \"economy\", \"people\", \"government\", \"media\", \"19\", \"control\"], \"Freq\": [700.0, 932.0, 565.0, 864.0, 530.0, 2117.0, 600.0, 607.0, 1048.0, 2118.0, 659.0, 347.0, 180.0, 469.0, 483.0, 231.0, 213.0, 82.0, 442.0, 235.0, 315.0, 139.0, 182.0, 196.0, 139.0, 107.0, 207.0, 263.0, 446.0, 124.0, 11.109230215066148, 14.511351382163452, 6.8160769144323385, 8.479176884457422, 11.858771295009936, 42.18578540509538, 6.724722165815684, 9.24432858205863, 5.878875696616173, 8.362225042953833, 6.664211652508564, 6.662163643582945, 6.658170260964465, 5.822233793683784, 10.78576488133232, 18.25369895440485, 5.801897259589746, 5.7731399406796875, 7.415169501155566, 4.930112586288535, 11.492629158184386, 4.922030564822479, 4.915662820070939, 4.914831340521871, 7.371570322606023, 8.193254579721712, 5.729887575302286, 13.103367718219886, 4.901826181975852, 4.898243340288418, 159.9699409559854, 198.20478240512074, 16.992332068325428, 711.8736382606448, 37.374336924569405, 181.11805812194376, 13.747682193479905, 211.6577525588658, 367.04784915146377, 18.314734047790527, 20.456913818152312, 12.80476090618822, 1423.6157316938156, 74.55234405278144, 93.81240225978358, 49.55725443410567, 119.55789093528354, 21.651044564495443, 23.725943921098963, 124.06754084928453, 122.98587014367003, 101.20835348130925, 126.53333017936082, 265.1049010975385, 252.01838031549877, 71.19689374221285, 141.19922607259608, 215.99757269111723, 178.30677042401572, 44.31737295110881, 51.00256780675966, 65.87497383813258, 47.18843862852582, 73.88566314660166, 221.74188286448728, 107.23007126000691, 94.6635689906238, 114.62090279462777, 110.68537693141143, 227.32021643765663, 263.7688023456386, 95.16501924679136, 149.87598986730757, 217.03162064873055, 370.9819153135919, 372.05745742125544, 124.47895116112439, 462.47859839487745, 296.5189350200753, 203.56856138452324, 184.46910249650728, 213.75190843175457, 187.22055318291703, 157.98858992454186, 245.90465843586216, 173.06304112601808, 164.85108479692283, 166.67398312862747, 157.23052207045671, 169.75588438196544, 36.15102799297036, 21.913589415745587, 8.31270534527661, 56.46551803907439, 9.116914945065586, 10.689200121778722, 7.391742944317435, 8.185453676955618, 29.382804539846035, 6.521837790827583, 6.506182276018902, 7.303058351809255, 8.096546023352822, 54.28976637612783, 5.658816290221162, 8.067143197049067, 5.623281470688942, 5.6205472540221635, 5.6180848344874805, 8.016275270340719, 5.608526947752631, 7.204237913147403, 5.6010340944007115, 12.776787043283548, 5.571303861896454, 7.161699475101034, 11.916878400865858, 6.337043857947576, 4.745181165050676, 7.082849565027746, 28.157243154284274, 135.05738703925647, 81.43816855602613, 753.4307075728934, 99.74131483751448, 15.228593368573765, 24.29610684180233, 10.799324821851759, 32.7087641765597, 1235.5062764227384, 292.0521891683759, 39.204900580647966, 139.9720390271469, 221.63050446971462, 35.6391296481293, 174.89661339017704, 122.41161995970464, 119.24950588242787, 287.94082704377223, 282.7127648456314, 611.3804439420056, 73.56605385972769, 54.02743653172349, 92.99194848196862, 113.6098615995658, 69.964355720093, 120.12102619818545, 462.1825480558605, 546.314844763733, 157.13464206599286, 166.30799396728028, 232.08862829317496, 252.90778375630137, 142.09798995764172, 122.20607884574136, 183.73266192642942, 225.0313701463917, 249.1439620638874, 202.6193710214089, 529.8375653846347, 210.4698219242269, 207.96955823162057, 162.75120296207763, 148.87304895243298, 203.487942182078, 182.9567042326745, 129.97488313971994, 167.14405444202484, 176.45788609688287, 135.84403167128116, 78.26325936412199, 17.724955417692446, 11.808591104319774, 15.842823252428182, 49.156094148874445, 13.335318911504778, 14.992459655800507, 9.070793204857432, 57.30584065352061, 19.56674894100227, 8.14508893052492, 13.778338227729769, 10.532283090858874, 7.278148506261648, 12.073327445028221, 7.247656691223668, 14.44535712999017, 7.208842424592164, 5.598624692992864, 6.385517747627109, 32.54493230730298, 5.5342902808687136, 9.480935476596226, 11.806055074599362, 5.493806439795042, 47.833063902508094, 7.0606884817444895, 4.6911943956450335, 4.68692416279437, 9.349369563690084, 14.759317264690832, 20.11819709979937, 29.045032056239535, 10.82771202639628, 138.8461088492423, 81.01415965294854, 460.8567720926053, 368.4065471254634, 333.7474811735601, 97.84702719298635, 87.7607880409548, 367.65165647373664, 354.1320380867126, 94.51775012532775, 509.6926491880567, 212.46820116173333, 133.31318998913474, 47.8582604737024, 93.19658118517822, 336.6063923727759, 119.80465671469088, 64.26202454663344, 86.1334824842261, 136.30658400937878, 75.4913469962256, 119.19487901060846, 225.38368091313922, 159.57587602207363, 99.82141810306413, 202.125970361349, 189.267998078316, 184.2963802359329, 313.1640540317309, 420.7544195155242, 236.25819014171913, 102.19908513305867, 114.55975775731878, 121.49299932787767, 103.1665921045597, 124.52684573656718, 147.0415642089648, 164.5290048893697, 125.01879586339841, 116.29948620954315, 124.86124663273502, 109.70118324583696], \"Total\": [700.0, 932.0, 565.0, 864.0, 530.0, 2117.0, 600.0, 607.0, 1048.0, 2118.0, 659.0, 347.0, 180.0, 469.0, 483.0, 231.0, 213.0, 82.0, 442.0, 235.0, 315.0, 139.0, 182.0, 196.0, 139.0, 107.0, 207.0, 263.0, 446.0, 124.0, 12.08649486183945, 15.807654447648797, 7.4369207451076, 9.293040101904337, 13.014347787380926, 46.49263406736333, 7.429140057887955, 10.218332468062005, 6.502959874558755, 9.28751250875889, 7.429665427285715, 7.428747590229369, 7.42848164304529, 6.499542921416852, 12.071268991382661, 20.439661204715215, 6.498786615714538, 6.4957892798027554, 8.352981794532644, 5.568175295836596, 12.99708653471157, 5.56782690213788, 5.566440260550501, 5.566676874081602, 8.350895315101868, 9.281964331906359, 6.494347723583234, 14.854918809002067, 5.5663985264052345, 5.565586460843672, 182.87344444224678, 231.12500500912174, 19.48749189479874, 864.5184494822314, 43.60941549257303, 218.656047689374, 15.77374525210774, 263.8685689911624, 469.0449632173272, 21.337938999137368, 24.1001289817843, 14.836290241715762, 2117.98230196782, 95.25988541009228, 121.92483949309633, 62.022727925697666, 158.88292852182232, 25.955239713869666, 28.7075656156937, 170.7568488189724, 169.70870941831106, 137.49690895820854, 175.35381098068942, 395.0129106042018, 378.46065916975544, 95.13298137963736, 202.79317293056687, 326.72929317445914, 264.239956744126, 57.303440397227966, 67.42386947160367, 90.36535357974381, 61.91831517372749, 103.34817112143092, 366.36015247804977, 159.3356244128078, 138.95754178817504, 174.7858715766495, 169.31344430324586, 403.3352587573758, 520.2587939030818, 143.41320680383845, 267.6829313398708, 500.47646211976246, 1129.4039234645622, 1231.5363562167195, 222.79199095142923, 2118.73929433314, 994.9596732176549, 521.2393028619808, 439.23247428055845, 587.9146663590403, 483.9878981946043, 350.43505848225027, 932.0551937208018, 475.616351610091, 465.2598470690812, 535.881253094472, 473.2829705713689, 1048.0478385875938, 37.69440697540227, 23.32012408651798, 8.974304844206491, 61.08894590408465, 9.873269923608873, 11.662882071681208, 8.076597012063678, 8.976228576129781, 32.293064344103094, 7.1803357890407735, 7.180702437940053, 8.076807658460595, 8.96992224583697, 60.268700415655786, 6.283348950886674, 8.980363811214758, 6.282054567618707, 6.283265875026409, 6.281077868032707, 8.977623801109104, 6.2828992430437784, 8.081882935416564, 6.283613349996831, 14.378150956105511, 6.2835387254072925, 8.084848559413047, 13.474349213149502, 7.176779422942288, 5.384992766762181, 8.074625363197706, 32.31803540081746, 163.26774534857614, 100.88111003530724, 1048.0478385875938, 129.90215196152513, 18.000762471174568, 29.606463142739937, 12.571559830597955, 41.26429166408344, 2118.73929433314, 441.8370202480282, 50.51092755889552, 203.03158453974703, 337.9146008702515, 45.98276340951693, 265.08844883607196, 181.28194348616415, 176.36347990000897, 473.2829705713689, 470.29278977779364, 1129.4039234645622, 105.95871804554125, 74.9422276787307, 139.62282726273017, 178.4791204459865, 104.52732458845315, 197.9447801106225, 994.9596732176549, 1231.5363562167195, 274.68616312927384, 298.3826452987269, 465.2598470690812, 535.881253094472, 256.97192261804395, 213.6474966455939, 367.3839753030576, 500.22059824531965, 587.9146663590403, 439.23247428055845, 2117.98230196782, 500.47646211976246, 521.2393028619808, 350.43505848225027, 307.2416454265183, 659.067808400062, 520.2587939030818, 237.1545174634265, 607.4342033071318, 932.0551937208018, 403.3352587573758, 82.03811048728055, 18.73549966100971, 12.4911690362456, 16.948764589846334, 52.62411452168189, 14.277777532616824, 16.061205776914427, 9.818636470445629, 62.46527184398261, 21.41521452016135, 8.9275135420135, 15.16950554988575, 11.614726346934491, 8.035773464678709, 13.384355880131265, 8.03566897542599, 16.06500784089099, 8.035269213569435, 6.250857707829842, 7.146159998569162, 36.611909218677084, 6.252362488851576, 10.71846060684812, 13.417834602318283, 6.2505724012939705, 54.42528747214759, 8.035971450739169, 5.360504452443063, 5.361411089539902, 10.717227403326676, 16.954614197753305, 23.292148815971167, 33.971127261622186, 12.496636897041936, 180.62354908919133, 107.08954093604419, 700.4381499037713, 565.4117356250995, 530.1106378282718, 139.4326210370392, 124.1208163475273, 600.6364721387647, 607.4342033071318, 139.02888639555954, 932.0551937208018, 347.6500551871215, 213.54632663517745, 66.33447291380055, 144.1818566574171, 659.067808400062, 196.40441353104626, 94.2554059149485, 134.74235389217893, 235.8445178944158, 116.43776440519244, 207.1566913583796, 483.9878981946043, 315.02044707270613, 172.9872112131563, 442.3156986501385, 446.9187488504639, 475.616351610091, 1231.5363562167195, 2118.73929433314, 994.9596732176549, 209.31704302806062, 272.5178133285958, 328.8352851188725, 215.37814279878774, 500.22059824531965, 1129.4039234645622, 2117.98230196782, 587.9146663590403, 535.881253094472, 1048.0478385875938, 521.2393028619808], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.3308, -8.0636, -8.8192, -8.6009, -8.2655, -6.9964, -8.8327, -8.5145, -8.9672, -8.6148, -8.8418, -8.8421, -8.8427, -8.9768, -8.3603, -7.8342, -8.9803, -8.9853, -8.735, -9.1432, -8.2968, -9.1448, -9.1461, -9.1463, -8.7409, -8.6352, -8.9928, -8.1657, -9.1489, -9.1497, -5.6635, -5.4492, -7.9058, -4.1706, -7.1175, -5.5394, -8.1177, -5.3836, -4.833, -7.8308, -7.7202, -8.1887, -3.4776, -6.427, -6.1972, -6.8354, -5.9547, -7.6635, -7.572, -5.9177, -5.9265, -6.1213, -5.898, -5.1584, -5.209, -6.4731, -5.7884, -5.3633, -5.555, -6.9472, -6.8067, -6.5508, -6.8844, -6.436, -5.337, -6.0636, -6.1882, -5.9969, -6.0318, -5.3122, -5.1635, -6.1829, -5.7287, -5.3585, -4.8224, -4.8195, -5.9144, -4.6019, -5.0464, -5.4225, -5.521, -5.3737, -5.5062, -5.676, -5.2336, -5.5849, -5.6335, -5.6225, -5.6808, -5.6042, -7.0798, -7.5804, -8.5497, -6.6339, -8.4574, -8.2983, -8.6671, -8.5651, -7.2871, -8.7923, -8.7947, -8.6792, -8.5761, -6.6732, -8.9343, -8.5797, -8.9406, -8.9411, -8.9415, -8.586, -8.9432, -8.6928, -8.9445, -8.1199, -8.9499, -8.6988, -8.1895, -8.8211, -9.1104, -8.7098, -7.3297, -5.7618, -6.2677, -4.0429, -6.0649, -7.9443, -7.4772, -8.288, -7.1799, -3.5483, -4.9906, -6.9987, -5.7261, -5.2665, -7.0941, -5.5033, -5.8601, -5.8863, -5.0047, -5.0231, -4.2518, -6.3693, -6.678, -6.135, -5.9347, -6.4195, -5.879, -4.5315, -4.3643, -5.6104, -5.5537, -5.2204, -5.1345, -5.711, -5.8618, -5.454, -5.2513, -5.1495, -5.3562, -4.3949, -5.3182, -5.3301, -5.5753, -5.6644, -5.3519, -5.4582, -5.8002, -5.5486, -5.4944, -5.756, -5.9357, -7.4208, -7.827, -7.5331, -6.4008, -7.7054, -7.5883, -8.0908, -6.2474, -7.322, -8.1984, -7.6727, -7.9414, -8.3109, -7.8048, -8.3151, -7.6254, -8.3205, -8.5733, -8.4418, -6.8132, -8.5848, -8.0465, -7.8272, -8.5922, -6.4281, -8.3413, -8.7501, -8.751, -8.0605, -7.6039, -7.2942, -6.927, -7.9137, -5.3624, -5.9012, -4.1627, -4.3866, -4.4854, -5.7124, -5.8212, -4.3887, -4.4261, -5.747, -4.062, -4.937, -5.4031, -6.4276, -5.7611, -4.4769, -5.5099, -6.1328, -5.8399, -5.3809, -5.9718, -5.5151, -4.878, -5.2233, -5.6924, -4.9869, -5.0526, -5.0793, -4.5491, -4.2538, -4.8309, -5.6689, -5.5547, -5.496, -5.6595, -5.4713, -5.3051, -5.1927, -5.4673, -5.5396, -5.4686, -5.5981], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.861, 0.8598, 0.8582, 0.8537, 0.8524, 0.8481, 0.8457, 0.8452, 0.8445, 0.8404, 0.8366, 0.8364, 0.8359, 0.8353, 0.8328, 0.8322, 0.8319, 0.8274, 0.8263, 0.8236, 0.8223, 0.8221, 0.821, 0.8208, 0.8206, 0.8206, 0.8201, 0.8199, 0.8182, 0.8176, 0.8115, 0.7917, 0.8083, 0.7511, 0.7911, 0.757, 0.8079, 0.7249, 0.7001, 0.7926, 0.7815, 0.7981, 0.5481, 0.7002, 0.6832, 0.721, 0.661, 0.764, 0.7548, 0.6259, 0.6233, 0.6389, 0.6191, 0.5466, 0.5387, 0.6555, 0.5833, 0.5315, 0.552, 0.6884, 0.6662, 0.6292, 0.6737, 0.6098, 0.4432, 0.5493, 0.5615, 0.5234, 0.5203, 0.3719, 0.2661, 0.5352, 0.3654, 0.1098, -0.1679, -0.2516, 0.3632, -0.5766, -0.2652, 0.0051, 0.0778, -0.0664, -0.0044, 0.1487, -0.3871, -0.0656, -0.0922, -0.2225, -0.1566, -0.875, 0.9746, 0.9542, 0.9398, 0.9377, 0.9367, 0.9292, 0.9278, 0.9242, 0.9219, 0.9202, 0.9177, 0.9157, 0.9139, 0.9119, 0.9117, 0.9091, 0.9056, 0.9049, 0.9048, 0.9031, 0.9028, 0.9014, 0.9014, 0.8983, 0.8961, 0.8951, 0.8936, 0.8919, 0.8899, 0.8853, 0.8786, 0.8267, 0.8023, 0.6863, 0.7522, 0.8491, 0.8187, 0.8644, 0.784, 0.477, 0.6024, 0.763, 0.6445, 0.5946, 0.7616, 0.6005, 0.6237, 0.6251, 0.5194, 0.5075, 0.4027, 0.6515, 0.6892, 0.61, 0.5647, 0.6149, 0.5169, 0.2496, 0.2036, 0.4579, 0.4318, 0.3209, 0.2655, 0.4239, 0.4578, 0.3235, 0.2176, 0.1578, 0.2427, -0.3693, 0.1502, 0.0976, 0.2494, 0.2918, -0.1588, -0.0287, 0.415, -0.274, -0.6479, -0.0719, 1.341, 1.3326, 1.3319, 1.3206, 1.3199, 1.3198, 1.3192, 1.3088, 1.3019, 1.2978, 1.2963, 1.2919, 1.2902, 1.289, 1.285, 1.2849, 1.2818, 1.2795, 1.2779, 1.2755, 1.2703, 1.2661, 1.2654, 1.2601, 1.259, 1.259, 1.2587, 1.2547, 1.2536, 1.2515, 1.2494, 1.2416, 1.2314, 1.2447, 1.125, 1.109, 0.9695, 0.9597, 0.9254, 1.0339, 1.0414, 0.8972, 0.8485, 1.0022, 0.7845, 0.8957, 0.9169, 1.0616, 0.9517, 0.7162, 0.8938, 1.005, 0.9406, 0.8398, 0.9547, 0.8354, 0.6238, 0.708, 0.8382, 0.6049, 0.5289, 0.44, 0.0188, -0.2285, -0.0497, 0.6711, 0.5215, 0.3924, 0.652, -0.0025, -0.6507, -1.1671, -0.16, -0.1397, -0.7394, -0.1704]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 3, 1, 2, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 3, 2, 3, 1, 2, 1, 2, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 3, 2, 3, 1, 2, 3, 1, 2, 2, 1, 2, 1, 2, 3, 1, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 2, 3, 1, 1, 1, 2, 3, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 3, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1], \"Freq\": [0.16220633614311084, 0.7184786536221321, 0.1192693648111109, 0.7873198637299027, 0.1364687763798498, 0.08398078546452295, 0.20543556175237318, 0.037351920318613306, 0.7563763864519194, 0.04846805601998994, 0.799722924329834, 0.1696381960699648, 0.9238803118305345, 0.8484406310444895, 0.11465413933033643, 0.022930827866067285, 0.07452767377436771, 0.8943320852924126, 0.19364191678522386, 0.1075788426584577, 0.7028484387019236, 0.13792312360025874, 0.18036100778495373, 0.67900614695512, 0.0747140922548596, 0.8965691070583153, 0.8034302865647495, 0.14401108910122867, 0.05305671703729478, 0.2548162199206237, 0.6983851953380058, 0.04718818887418958, 0.7247712885307503, 0.12374143950525006, 0.15320368700650008, 0.8982019458107863, 0.1531227123068618, 0.8268626464570538, 0.02449963396909789, 0.7999267393438909, 0.9101067038658307, 0.08273697307871188, 0.8360295957849239, 0.13933826596415397, 0.049827389869057596, 0.18270042951987786, 0.769556354644334, 0.26893902143879256, 0.6387301759171323, 0.08964634047959752, 0.923141838209762, 0.1997880674356992, 0.1881337635019501, 0.612683406802811, 0.2754142052272801, 0.09431993329701373, 0.6300571544240517, 0.8875507862109839, 0.063396484729356, 0.063396484729356, 0.6715384609959144, 0.28242271724127244, 0.04393242268197571, 0.20162298165595305, 0.14679567962670265, 0.6508531337665853, 0.0265291346976902, 0.9550488491168473, 0.0265291346976902, 0.9551015412899185, 0.7463237141351393, 0.17869722732813195, 0.07358121125276021, 0.030966401619380725, 0.898025646962041, 0.06193280323876145, 0.9549174138639775, 0.39137493830548165, 0.39904895670362833, 0.2110355059490342, 0.2758134596224478, 0.6729848414787726, 0.049646422732040604, 0.22009275804727282, 0.159216037736325, 0.622815677027389, 0.3020617281188387, 0.4433486654647471, 0.25415408844407666, 0.21805419913421278, 0.5833657795019199, 0.1987030689080164, 0.9598682741545026, 0.9285063539660676, 0.01600889535064645, 0.0640355814025858, 0.9125070349868478, 0.25683739813902, 0.5525895535718309, 0.19068231073957548, 0.8762298248552327, 0.06740229421963329, 0.06740229421963329, 0.03377640872463413, 0.8106338093912191, 0.13510563489853653, 0.9327480360027007, 0.1244404620063723, 0.8710832340446061, 0.8918694923707816, 0.30186681741951404, 0.4498015491350375, 0.24988974951946527, 0.9548759484427441, 0.7345619677217502, 0.12363914308187875, 0.14545781539044558, 0.11138804901542645, 0.8911043921234116, 0.17731231365606745, 0.6895478864402623, 0.13298423524205058, 0.11796198820407394, 0.8847149115305546, 0.1714174444922202, 0.3206141091428563, 0.507903539236208, 0.3284918639753964, 0.5409933393233618, 0.13015715365062877, 0.33786902068528707, 0.2394171206180511, 0.4228956616524454, 0.018373811998912363, 0.11024287199347417, 0.8819429759477934, 0.1868105664007814, 0.7205550418315854, 0.0934052832003907, 0.3686541484001963, 0.5563326239493871, 0.07373082968003926, 0.6836620652430416, 0.09355375629641621, 0.22308972655299253, 0.959637258827914, 0.18530332523435905, 0.10473666208898555, 0.7089866356792868, 0.06226182603533727, 0.933927390530059, 0.08002152965144636, 0.88023682616591, 0.8382334750791461, 0.11974763929702088, 0.9422355677044597, 0.9748349914925744, 0.8666790514278719, 0.8711160229978131, 0.7564086784054901, 0.11865234171066512, 0.11865234171066512, 0.266236647176795, 0.08588278941186936, 0.6441209205890202, 0.9166242203884676, 0.10552582529895531, 0.16582629689835834, 0.7236056591928364, 0.9325903043985913, 0.7824409785420812, 0.16416336607013693, 0.053299794178615884, 0.6708641487050706, 0.248093156879611, 0.0810100104096689, 0.8277841016184985, 0.06402749957270154, 0.10976142783891692, 0.35572614326519125, 0.5710340720835965, 0.07488971437161922, 0.3639984035868734, 0.42353085277164243, 0.21261588994560363, 0.6624215587755571, 0.06275572662084225, 0.27194148202364976, 0.1522309552746721, 0.7829020556983136, 0.06524183797485947, 0.08609759456484595, 0.9470735402133054, 0.8982468603858637, 0.09329697954583992, 0.09329697954583992, 0.8396728159125593, 0.16989365872825266, 0.17274901433713086, 0.6581594678464242, 0.3863732971372976, 0.14669788287031085, 0.46488765698337947, 0.8566792675339719, 0.12979988902029876, 0.012979988902029877, 0.1113540632675918, 0.8908325061407344, 0.12373354179850628, 0.866134792589544, 0.3233224941028162, 0.6062296764427805, 0.07072679558499105, 0.2381495154389212, 0.6017527934751313, 0.16160145690498226, 0.8360165512215988, 0.06966804593513323, 0.10450206890269985, 0.306437780279585, 0.21822084353243174, 0.47822865710298873, 0.05900135049365663, 0.9440216078985061, 0.20422835820286145, 0.1840931679575089, 0.6098086188592483, 0.07954462401444387, 0.8749908641588825, 0.07954462401444387, 0.221941933207543, 0.12484233742924293, 0.6450187433844218, 0.31170599879536376, 0.04452942839933768, 0.6382551403905067, 0.8914339482421895, 0.2268043249241759, 0.6747428666494233, 0.09639183809277475, 0.3801295227633891, 0.2493649669327833, 0.3679653780349607, 0.9226567771813474, 0.4189125594626925, 0.462169834624601, 0.11838833202206528, 0.08296180215462498, 0.8959874632699498, 0.016592360430924998, 0.898240125818851, 0.880640819812003, 0.09784897997911145, 0.01218945675443175, 0.03656837026329525, 0.9507776268456765, 0.1805580525756245, 0.30801079557018296, 0.5113282665376929, 0.046695773187728294, 0.9339154637545659, 0.8618865268098843, 0.10773581585123554, 0.16166013944264643, 0.7698101878221258, 0.06928291690399133, 0.9423190816596493, 0.9033689065486387, 0.0645263504677599, 0.0215087834892533, 0.12879876492730175, 0.8586584328486783, 0.2864861053467386, 0.6660801949311672, 0.050135068435679254, 0.04910872099037819, 0.9166961251537263, 0.032739147326918794, 0.7709667725691163, 0.02460532252880158, 0.20504435440667984, 0.02731351686761703, 0.08194055060285109, 0.901346056631362, 0.11110640469828376, 0.8332980352371282, 0.05555320234914188, 0.8667016553561346, 0.6952896784561684, 0.23669435862337648, 0.06410472212716446, 0.5074397647744137, 0.3517480187640822, 0.14223690376252504, 0.8711593618019492, 0.06224709068953299, 0.8714592696534619, 0.31163620491601546, 0.4721195200224665, 0.2164658668877712, 0.9220592684356825, 0.0768382723696402, 0.9552500583596899, 0.8751310032150437, 0.06731776947808028, 0.6736301435757668, 0.21192858449574684, 0.11353317026557867, 0.45086813141443377, 0.4651361102566627, 0.0856078730533735, 0.8711046958663708, 0.8396117636886591, 0.1813163858733215, 0.5481658177565534, 0.2698662487416878, 0.8235798789793599, 0.10757433812511302, 0.0694027987903955, 0.6610977482348528, 0.2509722933113793, 0.0856978562526661, 0.9412497779548035, 0.6059610972929186, 0.2920623306772175, 0.10372307070779688, 0.8669132851543054, 0.12384475502204363, 0.9422853468876399, 0.8608593003231132, 0.9489073821594749, 0.063260492143965, 0.063260492143965, 0.9606786975005802, 0.29850456053109703, 0.4643404274928176, 0.23719554304827914, 0.05337461066389873, 0.9607429919501771, 0.5565729695688799, 0.40396425210644515, 0.0359079335205729, 0.6579479162854912, 0.22313016291421006, 0.12014701079995926, 0.942168939975715, 0.6723380071103331, 0.25023816275876165, 0.07790433368904844, 0.8961061736116606, 0.06592172676370006, 0.9229041746918007, 0.8980164232620358, 0.14157912006235274, 0.2749268959350338, 0.5827791686287543, 0.35464053268173173, 0.4986460823161319, 0.14615488619610761, 0.3391983709156539, 0.17198790637976819, 0.48729906807600987, 0.07003891170846115, 0.9105058522099949, 0.2027450801834844, 0.22205413543905433, 0.5744443938532058, 0.09330771498695599, 0.09330771498695599, 0.8397694348826039, 0.36453391546097086, 0.48496029824718445, 0.15297405380951457, 0.3317254364983012, 0.6085154503917882, 0.05916122434364608, 0.560364455250038, 0.3735763035000253, 0.0635079715950043, 0.891242901420109, 0.9236752827952248, 0.838024093932753, 0.11971772770467899, 0.019002695039894414, 0.05700808511968324, 0.9311320569548263, 0.2840854669769977, 0.13992269269016305, 0.5766510971473386, 0.33912429619335427, 0.20347457771601257, 0.4566873855403838, 0.26393286755686446, 0.18883001906507374, 0.5471778961544751, 0.8298710772509426, 0.041493553862547126, 0.12448066158764139, 0.15838156982312462, 0.7721101528877325, 0.059393088683671734, 0.9433912065982025, 0.042881418481736475, 0.273324493816946, 0.04315649902372831, 0.683311234542365, 0.07421508706514067, 0.8905810447816881, 0.07421508706514067, 0.29488198122990084, 0.5715613710258571, 0.13469917661118927, 0.13944042606191198, 0.4403381875639326, 0.4219907630821021, 0.8979602355081333, 0.0695499722497601, 0.9041496392468814, 0.0695499722497601, 0.8463435224980681, 0.0769403202270971, 0.7160262169811624, 0.2709288388577371, 0.009676029959204897, 0.7678422044992692, 0.10470575515899125, 0.12215671435215647, 0.030942474924534114, 0.8663892978869552, 0.09282742477360234, 0.9115521068130915, 0.36373854560371577, 0.24809912359097377, 0.3868664300062642, 0.0905358196684057, 0.6601570184154582, 0.24897350408811567, 0.1530700232020238, 0.6696813515088542, 0.1817706525524033, 0.7590645815883331, 0.1776534127121631, 0.06460124098624112, 0.9112546500167125, 0.08284133181970113, 0.08284133181970113, 0.8476130539547239, 0.15411146435540432, 0.12368815478129366, 0.8658170834690556, 0.8807699326803101, 0.0978633258533678, 0.05887352470223846, 0.08831028705335768, 0.8536661081824576, 0.21384448162291897, 0.1782037346857658, 0.6109842332083399, 0.8435678816369139, 0.09372976462632376, 0.04686488231316188, 0.9549731370661411, 0.11895190284682768, 0.8029253442160869, 0.06938860999398282, 0.5628072306382483, 0.3371884729815056, 0.09917308028867813, 0.8613716527924286, 0.10767145659905357, 0.655588813143482, 0.28349786514312736, 0.06496826076196668, 0.8723544359516754, 0.051314966820686786, 0.051314966820686786, 0.9748847694120354, 0.9548646082755913, 0.43358682460489534, 0.4196001528434471, 0.1458610055122459, 0.9431630991716223, 0.08574209992469295, 0.15092570687581028, 0.6569707240476447, 0.1923562930770131, 0.3701848995667616, 0.5008383935315011, 0.13065349396473938, 0.2534871340955723, 0.6608771710348849, 0.08600456335385488, 0.8061560926487993, 0.16123121852975986, 0.03224624370595197, 0.7303684142812282, 0.06639712857102074, 0.19919138571306225, 0.7261787791098113, 0.22253865811429702, 0.04685024381353621, 0.8749220013216822, 0.021873050033042053, 0.10389698765694975, 0.20810786963690917, 0.21388864379348999, 0.578077415658081, 0.9549047883379629, 0.6658552055392565, 0.2932933643446725, 0.03963423842495574, 0.7242500136708503, 0.24521850856572094, 0.034216536078937806, 0.9232492701778459, 0.755273087652826, 0.15734855992767208, 0.08811519355949637, 0.8983779221070736], \"Term\": [\"19\", \"19\", \"19\", \"able\", \"able\", \"able\", \"access\", \"access\", \"access\", \"affecting\", \"affecting\", \"affecting\", \"affiliation\", \"afford\", \"afford\", \"afford\", \"affordability\", \"affordability\", \"affordable\", \"affordable\", \"affordable\", \"among\", \"among\", \"among\", \"availability\", \"availability\", \"back\", \"back\", \"back\", \"become\", \"become\", \"become\", \"better\", \"better\", \"better\", \"betterment\", \"biden\", \"biden\", \"biden\", \"billionaires\", \"bottom\", \"bottom\", \"boys\", \"boys\", \"brutality\", \"brutality\", \"brutality\", \"businesses\", \"businesses\", \"businesses\", \"cancer\", \"care\", \"care\", \"care\", \"change\", \"change\", \"change\", \"checks\", \"checks\", \"checks\", \"class\", \"class\", \"class\", \"climate\", \"climate\", \"climate\", \"closing\", \"closing\", \"closing\", \"closures\", \"come\", \"come\", \"come\", \"communism\", \"communism\", \"communism\", \"compass\", \"control\", \"control\", \"control\", \"corona\", \"corona\", \"corona\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"country\", \"country\", \"country\", \"covid\", \"covid\", \"covid\", \"crises\", \"cultures\", \"de\", \"de\", \"de\", \"debt\", \"debt\", \"debt\", \"decent\", \"decent\", \"decent\", \"decline\", \"decline\", \"decline\", \"del\", \"desempleo\", \"desempleo\", \"discussion\", \"division\", \"division\", \"division\", \"donations\", \"dont\", \"dont\", \"dont\", \"downturn\", \"downturn\", \"due\", \"due\", \"due\", \"economia\", \"economia\", \"economic\", \"economic\", \"economic\", \"economy\", \"economy\", \"economy\", \"education\", \"education\", \"education\", \"el\", \"el\", \"el\", \"elected\", \"elected\", \"elected\", \"election\", \"election\", \"election\", \"environment\", \"environment\", \"environment\", \"epa\", \"equality\", \"equality\", \"equality\", \"es\", \"es\", \"este\", \"este\", \"examples\", \"examples\", \"expense\", \"eyes\", \"fallout\", \"falta\", \"find\", \"find\", \"find\", \"gap\", \"gap\", \"gap\", \"gaps\", \"gender\", \"gender\", \"gender\", \"gente\", \"get\", \"get\", \"get\", \"getting\", \"getting\", \"getting\", \"global\", \"global\", \"global\", \"going\", \"going\", \"going\", \"government\", \"government\", \"government\", \"gun\", \"gun\", \"gun\", \"handled\", \"handled\", \"handled\", \"hardship\", \"hardship\", \"hating\", \"hay\", \"hay\", \"hay\", \"health\", \"health\", \"health\", \"healthcare\", \"healthcare\", \"healthcare\", \"help\", \"help\", \"help\", \"honestly\", \"honestly\", \"hypocrisy\", \"hypocrisy\", \"illegal\", \"illegal\", \"illegal\", \"immigration\", \"immigration\", \"immigration\", \"improve\", \"improve\", \"improve\", \"income\", \"income\", \"income\", \"inequalities\", \"inequalities\", \"inequality\", \"inequality\", \"inequality\", \"infection\", \"infection\", \"infection\", \"injustice\", \"injustice\", \"injustice\", \"insurance\", \"insurance\", \"insurance\", \"isnt\", \"issue\", \"issue\", \"issue\", \"issues\", \"issues\", \"issues\", \"jerrymandering\", \"jobs\", \"jobs\", \"jobs\", \"joe\", \"joe\", \"joe\", \"junk\", \"kill\", \"kill\", \"la\", \"la\", \"la\", \"lack\", \"lack\", \"lack\", \"las\", \"las\", \"leaves\", \"leaves\", \"left\", \"left\", \"left\", \"legally\", \"let\", \"let\", \"let\", \"lgbtq\", \"lgbtq\", \"life\", \"life\", \"life\", \"limits\", \"limits\", \"limits\", \"living\", \"living\", \"living\", \"los\", \"los\", \"los\", \"lose\", \"lose\", \"lose\", \"losses\", \"make\", \"make\", \"make\", \"many\", \"many\", \"many\", \"marginalized\", \"mas\", \"mas\", \"media\", \"media\", \"media\", \"meet\", \"meet\", \"militia\", \"million\", \"million\", \"money\", \"money\", \"money\", \"much\", \"much\", \"much\", \"muy\", \"na\", \"national\", \"national\", \"national\", \"need\", \"need\", \"need\", \"needs\", \"needs\", \"needs\", \"offended\", \"one\", \"one\", \"one\", \"overwhelming\", \"overwhelming\", \"owned\", \"owners\", \"package\", \"package\", \"package\", \"pandemia\", \"pandemic\", \"pandemic\", \"pandemic\", \"para\", \"para\", \"party\", \"party\", \"party\", \"pay\", \"pay\", \"pay\", \"paycheck\", \"people\", \"people\", \"people\", \"pero\", \"personas\", \"personas\", \"phones\", \"police\", \"police\", \"police\", \"political\", \"political\", \"political\", \"poor\", \"poor\", \"poor\", \"por\", \"por\", \"poverty\", \"poverty\", \"poverty\", \"prescription\", \"prescription\", \"prescription\", \"president\", \"president\", \"president\", \"problem\", \"problem\", \"problem\", \"problems\", \"problems\", \"problems\", \"proud\", \"proverty\", \"punishment\", \"punishment\", \"que\", \"que\", \"que\", \"race\", \"race\", \"race\", \"racial\", \"racial\", \"racial\", \"racism\", \"racism\", \"racism\", \"raise\", \"raise\", \"raise\", \"rate\", \"rate\", \"rate\", \"recession\", \"recession\", \"relations\", \"relations\", \"relations\", \"republic\", \"republic\", \"republic\", \"right\", \"right\", \"right\", \"rights\", \"rights\", \"rights\", \"road\", \"ruin\", \"ruin\", \"ruin\", \"safely\", \"safely\", \"see\", \"see\", \"see\", \"seem\", \"seem\", \"seem\", \"shutting\", \"shutting\", \"shutting\", \"slowly\", \"social\", \"social\", \"social\", \"socialism\", \"socialism\", \"socialism\", \"socialist\", \"socialist\", \"socialist\", \"something\", \"something\", \"something\", \"sometimes\", \"sometimes\", \"sometimes\", \"spend\", \"spend\", \"steal\", \"steal\", \"sustainability\", \"sustainability\", \"systematic\", \"systematic\", \"systematic\", \"systemic\", \"systemic\", \"systemic\", \"talk\", \"talk\", \"talk\", \"teacher\", \"term\", \"term\", \"term\", \"think\", \"think\", \"think\", \"tired\", \"tired\", \"together\", \"together\", \"together\", \"told\", \"told\", \"told\", \"trend\", \"tried\", \"trump\", \"trump\", \"trump\", \"twitter\", \"twitter\", \"unemployment\", \"unemployment\", \"unemployment\", \"us\", \"us\", \"us\", \"virus\", \"virus\", \"virus\", \"vote\", \"vote\", \"vote\", \"voter\", \"voter\", \"voter\", \"want\", \"want\", \"want\", \"warming\", \"warming\", \"warming\", \"wealth\", \"wealth\", \"wealth\", \"wins\", \"work\", \"work\", \"work\", \"working\", \"working\", \"working\", \"worrying\", \"would\", \"would\", \"would\", \"zero\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1782955774413442854649408\", ldavis_el1782955774413442854649408_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1782955774413442854649408\", ldavis_el1782955774413442854649408_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1782955774413442854649408\", ldavis_el1782955774413442854649408_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.054600  0.048871       1        1  38.854301\n",
       "2     -0.036763 -0.055675       2        1  36.190091\n",
       "0      0.091363  0.006804       3        1  24.955607, topic_info=           Term        Freq        Total Category  logprob  loglift\n",
       "13       health  700.000000   700.000000  Default  30.0000  30.0000\n",
       "16       racism  932.000000   932.000000  Default  29.0000  29.0000\n",
       "126     climate  565.000000   565.000000  Default  28.0000  28.0000\n",
       "56         need  864.000000   864.000000  Default  27.0000  27.0000\n",
       "125      change  530.000000   530.000000  Default  26.0000  26.0000\n",
       "..          ...         ...          ...      ...      ...      ...\n",
       "26       people  164.529005  2117.982302   Topic3  -5.1927  -1.1671\n",
       "69   government  125.018796   587.914666   Topic3  -5.4673  -0.1600\n",
       "332       media  116.299486   535.881253   Topic3  -5.5396  -0.1397\n",
       "19           19  124.861247  1048.047839   Topic3  -5.4686  -0.7394\n",
       "46      control  109.701183   521.239303   Topic3  -5.5981  -0.1704\n",
       "\n",
       "[276 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "19        1  0.162206        19\n",
       "19        2  0.718479        19\n",
       "19        3  0.119269        19\n",
       "67        1  0.787320      able\n",
       "67        2  0.136469      able\n",
       "...     ...       ...       ...\n",
       "1491      1  0.923249  worrying\n",
       "693       1  0.755273     would\n",
       "693       2  0.157349     would\n",
       "693       3  0.088115     would\n",
       "5552      1  0.898378      zero\n",
       "\n",
       "[519 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 9: Visualize the LDA Model using PyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('/Users/gytkd/Desktop/Backup-Thesis/lda-figure/anes/ldavis_' + str(best_num_topics))\n",
    "\n",
    "# Prepare the visualization\n",
    "if not os.path.exists(LDAvis_data_filepath):\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(best_lda_model, corpus, dictionary)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "else:\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "# Save the visualization as an HTML file\n",
    "html_filepath = '/Users/gytkd/Desktop/Backup-Thesis/lda-figure/anes/ldavis_' + str(best_num_topics) + '.html'\n",
    "pyLDAvis.save_html(LDAvis_prepared, html_filepath)\n",
    "\n",
    "# Display the visualization inline (in Jupyter Notebook)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd2163",
   "metadata": {},
   "source": [
    "## Connect the demographic information to the LDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f086b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract topic distribution for each document\n",
    "topic_distributions = [best_lda_model.get_document_topics(doc, minimum_probability=0) for doc in corpus]\n",
    "topic_df = pd.DataFrame([{i: prob for i, prob in doc} for doc in topic_distributions]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07dfd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign topics to each document\n",
    "most_probable_topics =  [max(topic, key=lambda x: x[1])[0] for topic in topic_distributions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633e267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "community= pd.DataFrame(most_probable_topics, index = index_save, columns = ['community'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5b0501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200015</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200022</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200039</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200046</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200053</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535414</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535421</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535469</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200411</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220170</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        community\n",
       "200015          0\n",
       "200022          1\n",
       "200039          0\n",
       "200046          2\n",
       "200053          0\n",
       "...           ...\n",
       "535414          1\n",
       "535421          2\n",
       "535469          1\n",
       "200411          0\n",
       "220170          0\n",
       "\n",
       "[7300 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8405b43",
   "metadata": {},
   "source": [
    "## Demographic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46fc622e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the demographcis dataset\n",
    "demos = pd.read_csv('/Users/gytkd/Desktop/Backup-Thesis/data/processed_data/anes_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "532b6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "demos.set_index('id_case', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1b99a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POST_vote</th>\n",
       "      <th>POST_president</th>\n",
       "      <th>PRE_present_religion</th>\n",
       "      <th>PRE_age</th>\n",
       "      <th>PRE_education</th>\n",
       "      <th>PRE_race</th>\n",
       "      <th>PRE_sex</th>\n",
       "      <th>PRE_occupation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200015</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200022</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200039</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200046</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200053</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535315</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535360</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535421</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535469</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8280 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         POST_vote  POST_president  PRE_present_religion  PRE_age   \n",
       "id_case                                                             \n",
       "200015          -1              -1                    11       46  \\\n",
       "200022           1               3                    12       37   \n",
       "200039           1               1                    11       40   \n",
       "200046           1               1                     2       41   \n",
       "200053           1               2                    12       72   \n",
       "...            ...             ...                   ...      ...   \n",
       "535315          -1              -1                    11       26   \n",
       "535360           1               2                     4       52   \n",
       "535414           1               1                     2       45   \n",
       "535421          -1              -1                     1       65   \n",
       "535469           1               1                     7       38   \n",
       "\n",
       "         PRE_education  PRE_race  PRE_sex  PRE_occupation  \n",
       "id_case                                                    \n",
       "200015               4         3        1               1  \n",
       "200022               3         4        2               1  \n",
       "200039               2         1        2               7  \n",
       "200046               3         4        1               1  \n",
       "200053               5         5        1               5  \n",
       "...                ...       ...      ...             ...  \n",
       "535315               3         1        2               1  \n",
       "535360               4         1        2               1  \n",
       "535414               2         3        1               1  \n",
       "535421               3         1        2               1  \n",
       "535469               5         4        2               1  \n",
       "\n",
       "[8280 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c37051",
   "metadata": {},
   "source": [
    "### filter only the YES vote to the president"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30b4bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "demos = demos[demos['POST_vote'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42e90e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POST_vote</th>\n",
       "      <th>POST_president</th>\n",
       "      <th>PRE_present_religion</th>\n",
       "      <th>PRE_age</th>\n",
       "      <th>PRE_education</th>\n",
       "      <th>PRE_race</th>\n",
       "      <th>PRE_sex</th>\n",
       "      <th>PRE_occupation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200022</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200039</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200046</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200053</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200060</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535292</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535308</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535360</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535469</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         POST_vote  POST_president  PRE_present_religion  PRE_age   \n",
       "id_case                                                             \n",
       "200022           1               3                    12       37  \\\n",
       "200039           1               1                    11       40   \n",
       "200046           1               1                     2       41   \n",
       "200053           1               2                    12       72   \n",
       "200060           1               1                    10       71   \n",
       "...            ...             ...                   ...      ...   \n",
       "535292           1               2                    11       65   \n",
       "535308           1               2                    11       54   \n",
       "535360           1               2                     4       52   \n",
       "535414           1               1                     2       45   \n",
       "535469           1               1                     7       38   \n",
       "\n",
       "         PRE_education  PRE_race  PRE_sex  PRE_occupation  \n",
       "id_case                                                    \n",
       "200022               3         4        2               1  \n",
       "200039               2         1        2               7  \n",
       "200046               3         4        1               1  \n",
       "200053               5         5        1               5  \n",
       "200060               3         1        2               5  \n",
       "...                ...       ...      ...             ...  \n",
       "535292               2         1        2               6  \n",
       "535308               4         1        2               1  \n",
       "535360               4         1        2               1  \n",
       "535414               2         3        1               1  \n",
       "535469               5         4        2               1  \n",
       "\n",
       "[5952 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6d14439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate indices \n",
    "duplicates = demos.index.duplicated() # no duplicates exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42d26998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants_ID converting from integer(index) to the original id from saved index.\n",
    "final_df.index = index_save \n",
    "topic_df.index = index_save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f0c53",
   "metadata": {},
   "source": [
    "### filter only the indices exist in demos for the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9812d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.loc[final_df.index.isin(demos.index)]\n",
    "topic_df = topic_df.loc[topic_df.index.isin(demos.index)]\n",
    "community = community.loc[community.index.isin(demos.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d12fe4b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200022</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200039</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200046</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200053</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200060</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535292</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535308</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535360</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535414</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535469</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5865 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        community\n",
       "200022          1\n",
       "200039          0\n",
       "200046          2\n",
       "200053          0\n",
       "200060          1\n",
       "...           ...\n",
       "535292          2\n",
       "535308          0\n",
       "535360          1\n",
       "535414          1\n",
       "535469          1\n",
       "\n",
       "[5865 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bdb6d",
   "metadata": {},
   "source": [
    "### Make two different dataframe for the analysis: Topic == community \n",
    "* merged_df for the topic distributions\n",
    "* community_df for the topic assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5187ff0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/9xtsbl9502ng_j6cfbbp6fq00000gn/T/ipykernel_13936/912597800.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  community['id'] = community.index\n",
      "/var/folders/j0/9xtsbl9502ng_j6cfbbp6fq00000gn/T/ipykernel_13936/912597800.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  demos['id'] = demos.index\n"
     ]
    }
   ],
   "source": [
    "# make a common column for the merge\n",
    "topic_df['id'] = topic_df.index\n",
    "community['id'] = community.index\n",
    "demos['id'] = demos.index\n",
    "\n",
    "# merged_df: for the topic distributions\n",
    "merged_df = pd.merge(topic_df, demos, on = 'id')\n",
    "# community_df: for the community label. Here topic == community\n",
    "community_df = pd.merge(community, demos, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71f9dce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "community_df.index = community_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3225bc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>id</th>\n",
       "      <th>POST_vote</th>\n",
       "      <th>POST_president</th>\n",
       "      <th>PRE_present_religion</th>\n",
       "      <th>PRE_age</th>\n",
       "      <th>PRE_education</th>\n",
       "      <th>PRE_race</th>\n",
       "      <th>PRE_sex</th>\n",
       "      <th>PRE_occupation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200022</th>\n",
       "      <td>1</td>\n",
       "      <td>200022</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200039</th>\n",
       "      <td>0</td>\n",
       "      <td>200039</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200046</th>\n",
       "      <td>2</td>\n",
       "      <td>200046</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200053</th>\n",
       "      <td>0</td>\n",
       "      <td>200053</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200060</th>\n",
       "      <td>1</td>\n",
       "      <td>200060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535292</th>\n",
       "      <td>2</td>\n",
       "      <td>535292</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535308</th>\n",
       "      <td>0</td>\n",
       "      <td>535308</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535360</th>\n",
       "      <td>1</td>\n",
       "      <td>535360</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535414</th>\n",
       "      <td>1</td>\n",
       "      <td>535414</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535469</th>\n",
       "      <td>1</td>\n",
       "      <td>535469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5865 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        community      id  POST_vote  POST_president  PRE_present_religion   \n",
       "id                                                                           \n",
       "200022          1  200022          1               3                    12  \\\n",
       "200039          0  200039          1               1                    11   \n",
       "200046          2  200046          1               1                     2   \n",
       "200053          0  200053          1               2                    12   \n",
       "200060          1  200060          1               1                    10   \n",
       "...           ...     ...        ...             ...                   ...   \n",
       "535292          2  535292          1               2                    11   \n",
       "535308          0  535308          1               2                    11   \n",
       "535360          1  535360          1               2                     4   \n",
       "535414          1  535414          1               1                     2   \n",
       "535469          1  535469          1               1                     7   \n",
       "\n",
       "        PRE_age  PRE_education  PRE_race  PRE_sex  PRE_occupation  \n",
       "id                                                                 \n",
       "200022       37              3         4        2               1  \n",
       "200039       40              2         1        2               7  \n",
       "200046       41              3         4        1               1  \n",
       "200053       72              5         5        1               5  \n",
       "200060       71              3         1        2               5  \n",
       "...         ...            ...       ...      ...             ...  \n",
       "535292       65              2         1        2               6  \n",
       "535308       54              4         1        2               1  \n",
       "535360       52              4         1        2               1  \n",
       "535414       45              2         3        1               1  \n",
       "535469       38              5         4        2               1  \n",
       "\n",
       "[5865 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98ba66f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community0</th>\n",
       "      <th>community1</th>\n",
       "      <th>community2</th>\n",
       "      <th>id</th>\n",
       "      <th>POST_vote</th>\n",
       "      <th>POST_president</th>\n",
       "      <th>PRE_present_religion</th>\n",
       "      <th>PRE_age</th>\n",
       "      <th>PRE_education</th>\n",
       "      <th>PRE_race</th>\n",
       "      <th>PRE_sex</th>\n",
       "      <th>PRE_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092491</td>\n",
       "      <td>0.797120</td>\n",
       "      <td>0.110389</td>\n",
       "      <td>200022</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938097</td>\n",
       "      <td>0.030269</td>\n",
       "      <td>0.031634</td>\n",
       "      <td>200039</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.209531</td>\n",
       "      <td>0.037027</td>\n",
       "      <td>0.753442</td>\n",
       "      <td>200046</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.967910</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.017432</td>\n",
       "      <td>200053</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020936</td>\n",
       "      <td>0.539041</td>\n",
       "      <td>0.440024</td>\n",
       "      <td>200060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   community0  community1  community2      id  POST_vote  POST_president   \n",
       "0    0.092491    0.797120    0.110389  200022          1               3  \\\n",
       "1    0.938097    0.030269    0.031634  200039          1               1   \n",
       "2    0.209531    0.037027    0.753442  200046          1               1   \n",
       "3    0.967910    0.014659    0.017432  200053          1               2   \n",
       "4    0.020936    0.539041    0.440024  200060          1               1   \n",
       "\n",
       "   PRE_present_religion  PRE_age  PRE_education  PRE_race  PRE_sex   \n",
       "0                    12       37              3         4        2  \\\n",
       "1                    11       40              2         1        2   \n",
       "2                     2       41              3         4        1   \n",
       "3                    12       72              5         5        1   \n",
       "4                    10       71              3         1        2   \n",
       "\n",
       "   PRE_occupation  \n",
       "0               1  \n",
       "1               7  \n",
       "2               1  \n",
       "3               5  \n",
       "4               5  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column name changed for the readability \n",
    "merged_df = merged_df.rename(columns = {0: 'community0', 1: 'community1', 2: 'community2'})\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd3358",
   "metadata": {},
   "source": [
    "### Create the community dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4582b3",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f350fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for community 0:\n",
      "        PRE_age\n",
      "id             \n",
      "200039       40\n",
      "200053       72\n",
      "200084       37\n",
      "200275       80\n",
      "200282       24\n",
      "...         ...\n",
      "534640       37\n",
      "534725       25\n",
      "534831       80\n",
      "535100       67\n",
      "535308       54\n",
      "\n",
      "[1778 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "community_dfs_age = {}\n",
    "\n",
    "# Loop over each community label and create a DataFrame for it\n",
    "for label in range(best_num_topics):\n",
    "    community_dfs_age[label] = community_df[community_df['community'] == label][['PRE_age']]\n",
    "\n",
    "# Display the DataFrame for a specific community, e.g., community 0\n",
    "print(f\"DataFrame for community 0:\\n{community_dfs_age[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4f385bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:         PRE_age\n",
       " id             \n",
       " 200039       40\n",
       " 200053       72\n",
       " 200084       37\n",
       " 200275       80\n",
       " 200282       24\n",
       " ...         ...\n",
       " 534640       37\n",
       " 534725       25\n",
       " 534831       80\n",
       " 535100       67\n",
       " 535308       54\n",
       " \n",
       " [1778 rows x 1 columns],\n",
       " 1:         PRE_age\n",
       " id             \n",
       " 200022       37\n",
       " 200060       71\n",
       " 200329       73\n",
       " 200374       50\n",
       " 200404       41\n",
       " ...         ...\n",
       " 534596       80\n",
       " 535254       47\n",
       " 535360       52\n",
       " 535414       45\n",
       " 535469       38\n",
       " \n",
       " [1709 rows x 1 columns],\n",
       " 2:         PRE_age\n",
       " id             \n",
       " 200046       41\n",
       " 200114       43\n",
       " 200121       37\n",
       " 200138       55\n",
       " 200152       30\n",
       " ...         ...\n",
       " 534534       49\n",
       " 534589       58\n",
       " 534992       46\n",
       " 535032       68\n",
       " 535292       65\n",
       " \n",
       " [2378 rows x 1 columns]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_dfs_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f386a4",
   "metadata": {},
   "source": [
    "### Political leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8808c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for community 0:\n",
      "        POST_president\n",
      "id                    \n",
      "200039               1\n",
      "200053               2\n",
      "200084               2\n",
      "200275               1\n",
      "200282               1\n",
      "...                ...\n",
      "534640               1\n",
      "534725               1\n",
      "534831               1\n",
      "535100               1\n",
      "535308               2\n",
      "\n",
      "[1778 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "community_dfs_politics = {}\n",
    "\n",
    "# Loop over each community label and create a DataFrame for it\n",
    "for label in range(best_num_topics):\n",
    "    community_dfs_politics[label] = community_df[community_df['community'] == label][['POST_president']]\n",
    "\n",
    "# Display the DataFrame for a specific community, e.g., community 0\n",
    "print(f\"DataFrame for community 0:\\n{community_dfs_politics[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b0e0f",
   "metadata": {},
   "source": [
    "### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3615cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for community 0:\n",
      "        PRE_present_religion\n",
      "id                          \n",
      "200039                    11\n",
      "200053                    12\n",
      "200084                     1\n",
      "200275                     2\n",
      "200282                    10\n",
      "...                      ...\n",
      "534640                     9\n",
      "534725                    12\n",
      "534831                     1\n",
      "535100                    12\n",
      "535308                    11\n",
      "\n",
      "[1778 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "community_dfs_religion = {}\n",
    "\n",
    "# Loop over each community label and create a DataFrame for it\n",
    "for label in range(best_num_topics):\n",
    "    community_dfs_religion[label] = community_df[community_df['community'] == label][['PRE_present_religion']]\n",
    "\n",
    "# Display the DataFrame for a specific community, e.g., community 0\n",
    "print(f\"DataFrame for community 0:\\n{community_dfs_religion[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6886e",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85b2ae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for community 0:\n",
      "        PRE_education\n",
      "id                   \n",
      "200039              2\n",
      "200053              5\n",
      "200084              3\n",
      "200275              1\n",
      "200282              4\n",
      "...               ...\n",
      "534640              3\n",
      "534725              3\n",
      "534831              5\n",
      "535100              1\n",
      "535308              4\n",
      "\n",
      "[1778 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "community_dfs_education = {}\n",
    "\n",
    "# Loop over each community label and create a DataFrame for it\n",
    "for label in range(best_num_topics):\n",
    "    community_dfs_education[label] = community_df[community_df['community'] == label][['PRE_education']]\n",
    "\n",
    "# Display the DataFrame for a specific community, e.g., community 0\n",
    "print(f\"DataFrame for community 0:\\n{community_dfs_education[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f11103",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "069fc84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for community 0:\n",
      "        PRE_race\n",
      "id              \n",
      "200039         1\n",
      "200053         5\n",
      "200084         1\n",
      "200275         3\n",
      "200282         1\n",
      "...          ...\n",
      "534640         5\n",
      "534725        -8\n",
      "534831         1\n",
      "535100         1\n",
      "535308         1\n",
      "\n",
      "[1778 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "community_dfs_race = {}\n",
    "\n",
    "# Loop over each community label and create a DataFrame for it\n",
    "for label in range(best_num_topics):\n",
    "    community_dfs_race[label] = community_df[community_df['community'] == label][['PRE_race']]\n",
    "\n",
    "# Display the DataFrame for a specific community, e.g., community 0\n",
    "print(f\"DataFrame for community 0:\\n{community_dfs_race[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0105050",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0dcdc4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for community 0:\n",
      "        PRE_sex\n",
      "id             \n",
      "200039        2\n",
      "200053        1\n",
      "200084        2\n",
      "200275        2\n",
      "200282        1\n",
      "...         ...\n",
      "534640        1\n",
      "534725        1\n",
      "534831        2\n",
      "535100        1\n",
      "535308        2\n",
      "\n",
      "[1778 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "community_dfs_sex = {}\n",
    "\n",
    "# Loop over each community label and create a DataFrame for it\n",
    "for label in range(best_num_topics):\n",
    "    community_dfs_sex[label] = community_df[community_df['community'] == label][['PRE_sex']]\n",
    "\n",
    "# Display the DataFrame for a specific community, e.g., community 0\n",
    "print(f\"DataFrame for community 0:\\n{community_dfs_sex[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247d931",
   "metadata": {},
   "source": [
    "### Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2fc3d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for community 0:\n",
      "        PRE_occupation\n",
      "id                    \n",
      "200039               7\n",
      "200053               5\n",
      "200084               1\n",
      "200275               5\n",
      "200282               1\n",
      "...                ...\n",
      "534640               1\n",
      "534725              -2\n",
      "534831               2\n",
      "535100               5\n",
      "535308               1\n",
      "\n",
      "[1778 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "community_dfs_job = {}\n",
    "\n",
    "# Loop over each community label and create a DataFrame for it\n",
    "for label in range(best_num_topics):\n",
    "    community_dfs_job[label] = community_df[community_df['community'] == label][['PRE_occupation']]\n",
    "\n",
    "# Display the DataFrame for a specific community, e.g., community 0\n",
    "print(f\"DataFrame for community 0:\\n{community_dfs_job[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573942ec",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a599eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting numpy>=1.22.3 (from statsmodels)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy!=1.9.2,>=1.8 (from statsmodels)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas!=2.1.0,>=1.4 in /Users/gytkd/miniforge3/lib/python3.9/site-packages (from statsmodels) (2.0.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/gytkd/miniforge3/lib/python3.9/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/gytkd/miniforge3/lib/python3.9/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gytkd/miniforge3/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gytkd/miniforge3/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/gytkd/miniforge3/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2023.4)\n",
      "Requirement already satisfied: six in /Users/gytkd/miniforge3/lib/python3.9/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.2-cp39-cp39-macosx_11_0_arm64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, statsmodels\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.1\n",
      "    Uninstalling numpy-1.22.1:\n",
      "      Successfully uninstalled numpy-1.22.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.3\n",
      "    Uninstalling scipy-1.7.3:\n",
      "      Successfully uninstalled scipy-1.7.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pymc 5.12.0 requires arviz>=0.13.0, but you have arviz 0.12.1 which is incompatible.\n",
      "pymc3 3.11.6 requires numpy<1.22.2,>=1.15.0, but you have numpy 2.0.2 which is incompatible.\n",
      "pymc3 3.11.6 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.13.1 which is incompatible.\n",
      "scikit-image 0.20.0 requires scipy<1.9.2,>=1.8; python_version <= \"3.9\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.0.2 scipy-1.13.1 statsmodels-0.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42cd0a16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'copy_if_needed' from 'scipy._lib._util' (/Users/gytkd/miniforge3/lib/python3.9/site-packages/scipy/_lib/_util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/statsmodels/api.py:123\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m genmod\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    114\u001b[0m     GEE,\n\u001b[1;32m    115\u001b[0m     GLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     families,\n\u001b[1;32m    122\u001b[0m )\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m graphics\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgofplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProbPlot, qqline, qqplot, qqplot_2samples\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayes_mi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MI, BayesGaussMI\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/statsmodels/graphics/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tsaplots \u001b[38;5;28;01mas\u001b[39;00m tsa\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magreement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_diff_plot\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m beanplot, violinplot\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/statsmodels/graphics/tsaplots.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_like\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstattools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m acf, pacf, ccf\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_data_corr_plot\u001b[39m(x, lags, zero):\n\u001b[1;32m     15\u001b[0m     zero \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(zero)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/statsmodels/tsa/stattools.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m correlate\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OLS, yule_walker\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msm_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     CollinearityWarning,\n\u001b[1;32m     24\u001b[0m     InfeasibleTestError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     ValueWarning,\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/signal/__init__.py:307\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=======================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mSignal processing (:mod:`scipy.signal`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _sigtools, windows\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_waveforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_max_len_seq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m max_len_seq\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/signal/windows/__init__.py:42\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mWindow functions (:mod:`scipy.signal.windows`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m==============================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_windows\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m windows\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/signal/windows/_windows.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg, special, fft \u001b[38;5;28;01mas\u001b[39;00m sp_fft\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxcar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriang\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparzen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbohman\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblackman\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnuttall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblackmanharris\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflattop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbartlett\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarthann\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhamming\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkaiser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkaiser_bessel_derived\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral_cosine\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral_gaussian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral_hamming\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchebwin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhann\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexponential\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtukey\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaylor\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdpss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_window\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanczos\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_len_guards\u001b[39m(M):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/fft/__init__.py:91\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_realtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dct, idct, dst, idst, dctn, idctn, dstn, idstn\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fftlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fht, ifht, fhtoffset\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m next_fast_len, fftfreq, rfftfreq, fftshift, ifftshift\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (set_backend, skip_backend, set_global_backend,\n\u001b[1;32m     93\u001b[0m                        register_backend)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pocketfft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_workers, get_workers\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/fft/_helper.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_wrapper, lru_cache\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pocketfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m helper \u001b[38;5;28;01mas\u001b[39;00m _helper\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_namespace\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/fft/_pocketfft/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" FFT backend using pypocketfft \"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrealtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/fft/_pocketfft/basic.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pypocketfft \u001b[38;5;28;01mas\u001b[39;00m pfft\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_asfarray, _init_nd_shape_and_axes, _datacopied,\n\u001b[1;32m      8\u001b[0m                      _fix_shape, _fix_shape_1d, _normalization,\n\u001b[1;32m      9\u001b[0m                      _workers)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mc2c\u001b[39m(forward, x, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overwrite_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m         workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, plan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124;03m\"\"\" Return discrete Fourier transform of real or complex sequence. \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/fft/_pocketfft/helper.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_if_needed\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# good_size is exposed (and used) from this import\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpypocketfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m good_size\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'copy_if_needed' from 'scipy._lib._util' (/Users/gytkd/miniforge3/lib/python3.9/site-packages/scipy/_lib/_util.py)"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import statsmodels.multivariate.manova as MANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6bb2f",
   "metadata": {},
   "source": [
    "## ANOVA: use the community label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65eb0a3",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, df_age in community_dfs_age.items():\n",
    "    print(f\"*community_{label} in age\")\n",
    "    print(\"how many:\", len(df_age))\n",
    "    print(\"mean:\", np.mean(df_age['PRE_age']))\n",
    "    print(\"variance:\", np.var(df_age['PRE_age']))\n",
    "    print(\"std:\", np.std(df_age['PRE_age']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e319060",
   "metadata": {},
   "source": [
    "## Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f00a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract age data from each community's DataFrame\n",
    "age_groups = [community_dfs_age[label]['PRE_age'].values for label in range(best_num_topics)]\n",
    "\n",
    "# Perform Levene's test for homogeneity of variances\n",
    "statistic, p_value = stats.levene(*age_groups)\n",
    "\n",
    "# Print the results\n",
    "print(\"Levene's Test Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Check the p-value against the significance level (commonly 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis. There is evidence of unequal variances.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. Variances are likely homogeneous.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28327b89",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71994e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(*age_groups)\n",
    "\n",
    "# Print the results\n",
    "print(\"ANOVA F-Statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Check the p-value against the significance level (commonly 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis. There is evidence of significant differences in means.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. Means are likely equal across groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa744138",
   "metadata": {},
   "source": [
    "**Result**: It means, there will be at least one population mean that differs from the rest, and it is not guaranteed that every population group(community) has different mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028694f",
   "metadata": {},
   "source": [
    "## Follow-up Analysis on the ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f753842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey = pairwise_tukeyhsd(endog=community_df['PRE_age'],\n",
    "                          groups=community_df['community'],\n",
    "                          alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6211f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbf375",
   "metadata": {},
   "source": [
    "**Result**: 'reject': True means that the means of the two groups are equal is rejected. \n",
    "'reject': False means that the means of the two groups are equal is not rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eefe15c",
   "metadata": {},
   "source": [
    "### Post-hoc analysis: standardized residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e05690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = community_df[['PRE_age', 'community']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceb570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataframe only with the age. \n",
    "\n",
    "# Calculate the group means\n",
    "group_means = df_age.groupby('community')['PRE_age'].mean()\n",
    "\n",
    "# Calculate residuals for each observation\n",
    "df_age['residual'] = df_age.apply(lambda row: row['PRE_age'] - group_means[row['community']], axis=1)\n",
    "\n",
    "# Calculate the standard deviation of the residuals\n",
    "residual_std = np.std(df_age['residual'], ddof=1)\n",
    "\n",
    "# Calculate standardized residuals\n",
    "df_age['standardized_residual'] = df_age['residual'] / residual_std\n",
    "\n",
    "# Display standardized residuals by group\n",
    "print(\"\\nStandardized Residuals by Group:\")\n",
    "for group, data in df_age.groupby('community'):\n",
    "    print(f\"\\nGroup {group}:\")\n",
    "    print(data[['PRE_age', 'residual', 'standardized_residual']].head())  # Show top few rows for each group\n",
    "\n",
    "# Summary statistics of standardized residuals by group\n",
    "print(\"\\nSummary of Standardized Residuals by Group:\")\n",
    "print(df_age.groupby('community')['standardized_residual'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254ed25",
   "metadata": {},
   "source": [
    "**Interpretation on the standardized residuals**\n",
    "* mean: all communities' are centered on 0 as it is standardized. \n",
    "* standard deviations(std): Groups with higher value suggests some observations in these groups are more atypical compared to others. Here, the deviations are alike between communities. \n",
    "* min and max: The ranges are bigger than expected, it means there are significant variations exist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172c755",
   "metadata": {},
   "source": [
    "## Chi-Square Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8b307",
   "metadata": {},
   "source": [
    "### First, check the expected frequencies\n",
    "* It is supposed to be >= 5 every cell in contingency_table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a189a",
   "metadata": {},
   "source": [
    "### Political leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80bb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([\n",
    "    df.assign(community_label = label)\n",
    "    for label, df in community_dfs_politics.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f072f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b69f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(combined_df['POST_president'], combined_df['community_label'])\n",
    "\n",
    "# Show the contingency table\n",
    "print(contingency_table) # it shows the change by the cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa613a32",
   "metadata": {},
   "source": [
    "### Cut off the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded95c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only rows with index 1 and 2\n",
    "contingency_table_filtered = contingency_table.loc[[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5854226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the table with only the people who voted for the Joe Biden/Donald Trump. \n",
    "contingency_table_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Chi-Square test\n",
    "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table_filtered)\n",
    "\n",
    "# Print the results\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Check if all expected frequencies are >= 5\n",
    "if np.all(expected >= 5):\n",
    "    print(\"All expected frequencies are >= 5. The Chi-Square test can be used.\")\n",
    "else:\n",
    "    print(\"Some expected frequencies are < 5. Consider using Fisher's Exact Test or combining categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a heatmap for the contingency table\n",
    "sns.heatmap(contingency_table_filtered, annot=True, fmt='d')\n",
    "plt.title(\"Contingency Table Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0131f",
   "metadata": {},
   "source": [
    "### Chi-Square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table_filtered)\n",
    "\n",
    "# Print the results in a readable format\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_filtered.index, \n",
    "                   columns=contingency_table_filtered.columns).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af68a7",
   "metadata": {},
   "source": [
    "### Influence of a label on the chi-square test: residuals calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8d337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals = contingency_table_filtered - expected\n",
    "\n",
    "# Standardize the residuals\n",
    "standardized_residuals = residuals / np.sqrt(expected)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "standardized_residuals_df = pd.DataFrame(standardized_residuals,\n",
    "                                         index=contingency_table_filtered.index,\n",
    "                                         columns=contingency_table_filtered.columns)\n",
    "\n",
    "# Print results\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_filtered.index, \n",
    "                   columns=contingency_table_filtered.columns).round(2))\n",
    "print(\"\\nStandardized Residuals:\")\n",
    "print(standardized_residuals_df.round(2))\n",
    "\n",
    "# Optional: if you want to see which residuals are extreme\n",
    "print(\"\\nExtreme Standardized Residuals (|value| > 2):\")\n",
    "print(standardized_residuals_df[standardized_residuals_df.abs() > 2].dropna(how='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1e926",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "* The distribution of the feature(**political leaning**) **is significantly different** across different clusters. \n",
    "* Extreme Standard residuals exist in all cells except community 1. It means that substantial deviations from expected counts in specific community-label combinations. It highlights where the actual distribution of 'POST_president' significantly differs from what was expected under the null hypothesis. In other words, the variable 'POST_president' is distributed unevenly across the communities, but not in Community 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17e143",
   "metadata": {},
   "source": [
    "### Pairwise Comparison with residuals interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique pairs of columns (communities)\n",
    "pairs = list(itertools.combinations(contingency_table_filtered.columns, 2))\n",
    "\n",
    "# Store results for pairwise comparisons\n",
    "pairwise_results = []\n",
    "pairwise_residuals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pairwise chi-squared tests\n",
    "for pair in pairs:\n",
    "    # Create a contingency table for each pair of communities\n",
    "    pair_table = contingency_table_filtered.loc[:, pair]\n",
    "    \n",
    "    # Perform chi-squared test\n",
    "    chi2_pair, p_pair, dof_pair, expected = stats.chi2_contingency(pair_table)\n",
    "    \n",
    "    # Calculate residuals and standardized residuals\n",
    "    residuals = pair_table - expected\n",
    "    standardized_residuals = residuals / np.sqrt(expected)\n",
    "    \n",
    "    # Append results\n",
    "    pairwise_results.append((pair, chi2_pair, p_pair))\n",
    "    pairwise_residuals[pair] = standardized_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-values for correction\n",
    "p_values = [result[2] for result in pairwise_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ecd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bonferroni correction\n",
    "adjusted_p_values = multipletests(p_values, method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d90617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print pairwise results with adjusted p-values\n",
    "print(\"\\nPairwise Chi-Squared Test Results (with Bonferroni correction):\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'Community Pair':<25}{'Chi2':<10}{'p-value':<15}{'Adj. p-value':<15}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for i, (pair, chi2_pair, p_pair) in enumerate(pairwise_results):\n",
    "    print(f\"{str(pair):<25}{chi2_pair:<10.4f}{p_pair:<15.4e}{adjusted_p_values[i]:<15.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eab0d",
   "metadata": {},
   "source": [
    "* Result: Comparing pairwise, \n",
    "    * (0, 1) community: adjusted p-value is <<< 0.05 : signiciant difference\n",
    "    * (0, 2) community: adjusted p-value is << 0.05 : signiciant difference\n",
    "    * (1, 2) community: adjusted p-value << 0.05: significant difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec015b9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print standardized residuals for each pairwise comparison\n",
    "print(\"\\nStandardized Residuals for Each Pairwise Comparison:\")\n",
    "for pair, residuals_df in pairwise_residuals.items():\n",
    "    print(f\"\\nPair: {pair}\")\n",
    "    print(pd.DataFrame(residuals_df, index=contingency_table_filtered.index, columns=pair).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645535d0",
   "metadata": {},
   "source": [
    "**Interpretation: Residuals**\n",
    "* Significant deviations from expected frequencies are observed in all pairs but especially the most on (0, 2).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0410155",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd60263",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([\n",
    "    df.assign(community_label = label)\n",
    "    for label, df in community_dfs_education.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7204e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991ec38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(combined_df['PRE_education'], combined_df['community_label'])\n",
    "\n",
    "# Show the contingency table\n",
    "print(contingency_table) # it shows the change by the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef09eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the table with only the people who voted for the Joe Biden/Donald Trump. \n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ffc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_filtered = contingency_table.loc[[-2, 1, 2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee006964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Chi-Square test\n",
    "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table_filtered)\n",
    "\n",
    "# Print the results\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Check if all expected frequencies are >= 5\n",
    "if np.all(expected >= 5):\n",
    "    print(\"All expected frequencies are >= 5. The Chi-Square test can be used.\")\n",
    "else:\n",
    "    print(\"Some expected frequencies are < 5. Consider using Fisher's Exact Test or combining categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a heatmap for the contingency table\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d')\n",
    "plt.title(\"Contingency Table Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998d9e9",
   "metadata": {},
   "source": [
    "### Chi-Square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68869522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table_filtered)\n",
    "\n",
    "# Print the results in a readable format\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_filtered.index, \n",
    "                   columns=contingency_table_filtered.columns).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0614968e",
   "metadata": {},
   "source": [
    "**Result**: It says, the educationn shows the significant difference between the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd13cd2",
   "metadata": {},
   "source": [
    "### Influence of a label on the chi-square test: residuals calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4a7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals = contingency_table_filtered - expected\n",
    "\n",
    "# bStandardize the residuals\n",
    "standardized_residuals = residuals / np.sqrt(expected)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "standardized_residuals_df = pd.DataFrame(standardized_residuals,\n",
    "                                         index=contingency_table_filtered.index,\n",
    "                                         columns=contingency_table_filtered.columns)\n",
    "\n",
    "# Print results\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_filtered.index, \n",
    "                   columns=contingency_table_filtered.columns).round(2))\n",
    "print(\"\\nStandardized Residuals:\")\n",
    "print(standardized_residuals_df.round(2))\n",
    "\n",
    "# Optional: if you want to see which residuals are extreme\n",
    "print(\"\\nExtreme Standardized Residuals (|value| > 2):\")\n",
    "print(standardized_residuals_df[standardized_residuals_df.abs() > 2].dropna(how='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6583c82",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "* The distribution of the feature(**education**) **is significantly different** across different clusters. \n",
    "* The extreme standardized residuals showed that community 0 is outstandingly different between the communities for its distributions regarding the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0113c2",
   "metadata": {},
   "source": [
    "### Pairwise Comparison with residuals interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee31916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique pairs of columns (communities)\n",
    "pairs = list(itertools.combinations(contingency_table_filtered.columns, 2))\n",
    "\n",
    "# Store results for pairwise comparisons\n",
    "pairwise_results = []\n",
    "pairwise_residuals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23117c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pairwise chi-squared tests\n",
    "for pair in pairs:\n",
    "    # Create a contingency table for each pair of communities\n",
    "    pair_table = contingency_table_filtered.loc[:, pair]\n",
    "    \n",
    "    # Perform chi-squared test\n",
    "    chi2_pair, p_pair, dof_pair, expected = stats.chi2_contingency(pair_table)\n",
    "    \n",
    "    # Calculate residuals and standardized residuals\n",
    "    residuals = pair_table - expected\n",
    "    standardized_residuals = residuals / np.sqrt(expected)\n",
    "    \n",
    "    # Append results\n",
    "    pairwise_results.append((pair, chi2_pair, p_pair))\n",
    "    pairwise_residuals[pair] = standardized_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-values for correction\n",
    "p_values = [result[2] for result in pairwise_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bonferroni correction\n",
    "adjusted_p_values = multipletests(p_values, method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceff9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print pairwise results with adjusted p-values\n",
    "print(\"\\nPairwise Chi-Squared Test Results (with Bonferroni correction):\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'Community Pair':<25}{'Chi2':<10}{'p-value':<15}{'Adj. p-value':<15}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for i, (pair, chi2_pair, p_pair) in enumerate(pairwise_results):\n",
    "    print(f\"{str(pair):<25}{chi2_pair:<10.4f}{p_pair:<15.4e}{adjusted_p_values[i]:<15.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc869e",
   "metadata": {},
   "source": [
    "* Result: Comparing pairwise, \n",
    "    * (0, 1) community: adjusted p-value is << 0.05 : signiciant difference\n",
    "    * (0, 2) community: adjusted p-value is << 0.05 : signiciant difference\n",
    "    * (1, 2) community: adjusted p-value is > 0.05 : no signiciant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2cd17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print standardized residuals for each pairwise comparison\n",
    "print(\"\\nStandardized Residuals for Each Pairwise Comparison:\")\n",
    "for pair, residuals_df in pairwise_residuals.items():\n",
    "    print(f\"\\nPair: {pair}\")\n",
    "    print(pd.DataFrame(residuals_df, index=contingency_table_filtered.index, columns=pair).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c53ee7",
   "metadata": {},
   "source": [
    "**Interpretation: Residuals**\n",
    "* compared to the pair (1, 2), the other pairs show more discrepancies in their distributions as having bigger absolute values of the standardized residuals when comparing between the 2 community. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c63002b",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fb949",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([\n",
    "    df.assign(community_label = label)\n",
    "    for label, df in community_dfs_sex.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1c51c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50850fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(combined_df['PRE_sex'], combined_df['community_label'])\n",
    "\n",
    "# Show the contingency table\n",
    "print(contingency_table) # it shows the change by the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a92a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_filtered = contingency_table.loc[[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fcbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Chi-Square test\n",
    "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table_filtered)\n",
    "\n",
    "# Print the results\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Check if all expected frequencies are >= 5\n",
    "if np.all(expected >= 5):\n",
    "    print(\"All expected frequencies are >= 5. The Chi-Square test can be used.\")\n",
    "else:\n",
    "    print(\"Some expected frequencies are < 5. Consider using Fisher's Exact Test or combining categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d08c0",
   "metadata": {},
   "source": [
    "### Chi-Square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table_filtered)\n",
    "\n",
    "# Print the results in a readable format\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_filtered.index, \n",
    "                   columns=contingency_table_filtered.columns).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732d08e",
   "metadata": {},
   "source": [
    "**Result**: It says, the sex shows the significant difference between the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b9725",
   "metadata": {},
   "source": [
    "### Influence of a label on the chi-square test: residuals calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f2f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals = contingency_table_filtered - expected\n",
    "\n",
    "# bStandardize the residuals\n",
    "standardized_residuals = residuals / np.sqrt(expected)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "standardized_residuals_df = pd.DataFrame(standardized_residuals,\n",
    "                                         index=contingency_table_filtered.index,\n",
    "                                         columns=contingency_table_filtered.columns)\n",
    "\n",
    "# Print results\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_filtered.index, \n",
    "                   columns=contingency_table_filtered.columns).round(2))\n",
    "print(\"\\nStandardized Residuals:\")\n",
    "print(standardized_residuals_df.round(2))\n",
    "\n",
    "# Optional: if you want to see which residuals are extreme\n",
    "print(\"\\nExtreme Standardized Residuals (|value| > 2):\")\n",
    "print(standardized_residuals_df[standardized_residuals_df.abs() > 2].dropna(how='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abd98f",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "* The distribution of the feature(**sex**) is **not significantly different** across different clusters. \n",
    "* The lack of extreme residuals tell that the difference of distributions of the variable is not influenced by a specific cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc998d21",
   "metadata": {},
   "source": [
    "### Pairwise Comparison with residuals interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ebc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique pairs of columns (communities)\n",
    "pairs = list(itertools.combinations(contingency_table_filtered.columns, 2))\n",
    "\n",
    "# Store results for pairwise comparisons\n",
    "pairwise_results = []\n",
    "pairwise_residuals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f55311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pairwise chi-squared tests\n",
    "for pair in pairs:\n",
    "    # Create a contingency table for each pair of communities\n",
    "    pair_table = contingency_table_filtered.loc[:, pair]\n",
    "    \n",
    "    # Perform chi-squared test\n",
    "    chi2_pair, p_pair, dof_pair, expected = stats.chi2_contingency(pair_table)\n",
    "    \n",
    "    # Calculate residuals and standardized residuals\n",
    "    residuals = pair_table - expected\n",
    "    standardized_residuals = residuals / np.sqrt(expected)\n",
    "    \n",
    "    # Append results\n",
    "    pairwise_results.append((pair, chi2_pair, p_pair))\n",
    "    pairwise_residuals[pair] = standardized_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-values for correction\n",
    "p_values = [result[2] for result in pairwise_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf958725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bonferroni correction\n",
    "adjusted_p_values = multipletests(p_values, method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d80aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print pairwise results with adjusted p-values\n",
    "print(\"\\nPairwise Chi-Squared Test Results (with Bonferroni correction):\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'Community Pair':<25}{'Chi2':<10}{'p-value':<15}{'Adj. p-value':<15}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for i, (pair, chi2_pair, p_pair) in enumerate(pairwise_results):\n",
    "    print(f\"{str(pair):<25}{chi2_pair:<10.4f}{p_pair:<15.4e}{adjusted_p_values[i]:<15.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616d68e",
   "metadata": {},
   "source": [
    "* Result: Comparing pairwise, \n",
    "    * (0, 1) community: adjusted p-value is > 0.05 : no signiciant difference\n",
    "    * (0, 2) community: adjusted p-value is > 0.05 : no signiciant difference\n",
    "    * (1, 2) community: adjusted p-value > 0.05: no significant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb735121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print standardized residuals for each pairwise comparison\n",
    "print(\"\\nStandardized Residuals for Each Pairwise Comparison:\")\n",
    "for pair, residuals_df in pairwise_residuals.items():\n",
    "    print(f\"\\nPair: {pair}\")\n",
    "    print(pd.DataFrame(residuals_df, index=contingency_table_filtered.index, columns=pair).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6f630",
   "metadata": {},
   "source": [
    "**Interpretation: Residuals**\n",
    "* compared to the other pair, pair (1, 2) showed the most difference to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d4ef1",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([\n",
    "    df.assign(community_label = label)\n",
    "    for label, df in community_dfs_job.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2124aba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c128c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(combined_df['PRE_occupation'], combined_df['community_label'])\n",
    "\n",
    "# Show the contingency table\n",
    "print(contingency_table) # it shows the change by the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7240ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Chi-Square test\n",
    "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Check if all expected frequencies are >= 5\n",
    "if np.all(expected >= 5):\n",
    "    print(\"All expected frequencies are >= 5. The Chi-Square test can be used.\")\n",
    "else:\n",
    "    print(\"Some expected frequencies are < 5. Consider using Fisher's Exact Test or combining categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6107cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a heatmap for the contingency table\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d')\n",
    "plt.title(\"Contingency Table Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ea6d4",
   "metadata": {},
   "source": [
    "### Chi-Square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362eab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results in a readable format\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table.index, \n",
    "                   columns=contingency_table.columns).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5888fb0",
   "metadata": {},
   "source": [
    "**Result**: It says, the Employment shows the significant difference between the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d24b7",
   "metadata": {},
   "source": [
    "### Influence of a label on the chi-square test: residuals calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59a5d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals = contingency_table - expected\n",
    "\n",
    "# bStandardize the residuals\n",
    "standardized_residuals = residuals / np.sqrt(expected)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "standardized_residuals_df = pd.DataFrame(standardized_residuals,\n",
    "                                         index=contingency_table.index,\n",
    "                                         columns=contingency_table.columns)\n",
    "\n",
    "# Print results\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table.index, \n",
    "                   columns=contingency_table.columns).round(2))\n",
    "print(\"\\nStandardized Residuals:\")\n",
    "print(standardized_residuals_df.round(2))\n",
    "\n",
    "# Optional: if you want to see which residuals are extreme\n",
    "print(\"\\nExtreme Standardized Residuals (|value| > 2):\")\n",
    "print(standardized_residuals_df[standardized_residuals_df.abs() > 2].dropna(how='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c4453",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "* The distribution of the feature(**Jobs**) **is significantly different** across different clusters. \n",
    "* Residuals: needs to be filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b8cec",
   "metadata": {},
   "source": [
    "### Pairwise Comparison with residuals interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique pairs of columns (communities)\n",
    "pairs = list(itertools.combinations(contingency_table.columns, 2))\n",
    "\n",
    "# Store results for pairwise comparisons\n",
    "pairwise_results = []\n",
    "pairwise_residuals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pairwise chi-squared tests\n",
    "for pair in pairs:\n",
    "    # Create a contingency table for each pair of communities\n",
    "    pair_table = contingency_table.loc[:, pair]\n",
    "    \n",
    "    # Perform chi-squared test\n",
    "    chi2_pair, p_pair, dof_pair, expected = stats.chi2_contingency(pair_table)\n",
    "    \n",
    "    # Calculate residuals and standardized residuals\n",
    "    residuals = pair_table - expected\n",
    "    standardized_residuals = residuals / np.sqrt(expected)\n",
    "    \n",
    "    # Append results\n",
    "    pairwise_results.append((pair, chi2_pair, p_pair))\n",
    "    pairwise_residuals[pair] = standardized_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-values for correction\n",
    "p_values = [result[2] for result in pairwise_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bonferroni correction\n",
    "adjusted_p_values = multipletests(p_values, method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53204d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print pairwise results with adjusted p-values\n",
    "print(\"\\nPairwise Chi-Squared Test Results (with Bonferroni correction):\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'Community Pair':<25}{'Chi2':<10}{'p-value':<15}{'Adj. p-value':<15}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for i, (pair, chi2_pair, p_pair) in enumerate(pairwise_results):\n",
    "    print(f\"{str(pair):<25}{chi2_pair:<10.4f}{p_pair:<15.4e}{adjusted_p_values[i]:<15.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236ce86",
   "metadata": {},
   "source": [
    "* Result: Comparing pairwise, \n",
    "    * (0, 1) community: adjusted p-value is needs to be filled. \n",
    "    * (0, 2) community: adjusted p-value is needs to be filled. \n",
    "    * (1, 2) community: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c13efd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print standardized residuals for each pairwise comparison\n",
    "print(\"\\nStandardized Residuals for Each Pairwise Comparison:\")\n",
    "for pair, residuals_df in pairwise_residuals.items():\n",
    "    print(f\"\\nPair: {pair}\")\n",
    "    print(pd.DataFrame(residuals_df, index=contingency_table.index, columns=pair).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a59160",
   "metadata": {},
   "source": [
    "**Interpretation: Residuals**\n",
    "* Extreme Residuals: needs to be filled\n",
    "* Moderate Residuals: needs to be filled\n",
    "* Small Residuals: needs to be filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12f71c",
   "metadata": {},
   "source": [
    "### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([\n",
    "    df.assign(community_label = label)\n",
    "    for label, df in community_dfs_religion.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdab100",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef554a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(combined_df['PRE_present_religion'], combined_df['community_label'])\n",
    "\n",
    "# Show the contingency table\n",
    "print(contingency_table) # it shows the change by the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Chi-Square test\n",
    "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Check if all expected frequencies are >= 5\n",
    "if np.all(expected >= 5):\n",
    "    print(\"All expected frequencies are >= 5. The Chi-Square test can be used.\")\n",
    "else:\n",
    "    print(\"Some expected frequencies are < 5. Consider using Fisher's Exact Test or combining categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a heatmap for the contingency table\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d')\n",
    "plt.title(\"Contingency Table Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643212d",
   "metadata": {},
   "source": [
    "### Chi-Square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results in a readable format\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table.index, \n",
    "                   columns=contingency_table.columns).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c143a7",
   "metadata": {},
   "source": [
    "**Result**: It says, the Religion shows the significant difference between the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e1cbe",
   "metadata": {},
   "source": [
    "### Influence of a label on the chi-square test: residuals calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f73223a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals = contingency_table - expected\n",
    "\n",
    "# bStandardize the residuals\n",
    "standardized_residuals = residuals / np.sqrt(expected)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "standardized_residuals_df = pd.DataFrame(standardized_residuals,\n",
    "                                         index=contingency_table.index,\n",
    "                                         columns=contingency_table.columns)\n",
    "\n",
    "# Print results\n",
    "print(f\"{'Chi-Squared Test Results':^40}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Test Statistic (Chi2):':<25} {chi2:.4f}\")\n",
    "print(f\"{'Degrees of Freedom:':<25} {dof}\")\n",
    "print(f\"{'p-value:':<25} {p:.4e}\")\n",
    "print(\"\\nExpected Frequencies (rounded):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table.index, \n",
    "                   columns=contingency_table.columns).round(2))\n",
    "print(\"\\nStandardized Residuals:\")\n",
    "print(standardized_residuals_df.round(2))\n",
    "\n",
    "# Optional: if you want to see which residuals are extreme\n",
    "print(\"\\nExtreme Standardized Residuals (|value| > 2):\")\n",
    "print(standardized_residuals_df[standardized_residuals_df.abs() > 2].dropna(how='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ac1e5",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "* The distribution of the feature(**religion**) **is significantly different** across different clusters. \n",
    "* Residuals: needs to be filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e7250",
   "metadata": {},
   "source": [
    "### Pairwise Comparison with residuals interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85559827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee440dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique pairs of columns (communities)\n",
    "pairs = list(itertools.combinations(contingency_table.columns, 2))\n",
    "\n",
    "# Store results for pairwise comparisons\n",
    "pairwise_results = []\n",
    "pairwise_residuals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df5c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pairwise chi-squared tests\n",
    "for pair in pairs:\n",
    "    # Create a contingency table for each pair of communities\n",
    "    pair_table = contingency_table.loc[:, pair]\n",
    "    \n",
    "    # Perform chi-squared test\n",
    "    chi2_pair, p_pair, dof_pair, expected = stats.chi2_contingency(pair_table)\n",
    "    \n",
    "    # Calculate residuals and standardized residuals\n",
    "    residuals = pair_table - expected\n",
    "    standardized_residuals = residuals / np.sqrt(expected)\n",
    "    \n",
    "    # Append results\n",
    "    pairwise_results.append((pair, chi2_pair, p_pair))\n",
    "    pairwise_residuals[pair] = standardized_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-values for correction\n",
    "p_values = [result[2] for result in pairwise_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c782a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bonferroni correction\n",
    "adjusted_p_values = multipletests(p_values, method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7b3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print pairwise results with adjusted p-values\n",
    "print(\"\\nPairwise Chi-Squared Test Results (with Bonferroni correction):\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'Community Pair':<25}{'Chi2':<10}{'p-value':<15}{'Adj. p-value':<15}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for i, (pair, chi2_pair, p_pair) in enumerate(pairwise_results):\n",
    "    print(f\"{str(pair):<25}{chi2_pair:<10.4f}{p_pair:<15.4e}{adjusted_p_values[i]:<15.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd261c",
   "metadata": {},
   "source": [
    "* Result: Comparing pairwise, \n",
    "    * (0, 1) community: adjusted p-value is needs to be filled\n",
    "    * (0, 2) community: adjusted p-value is needs to be filled\n",
    "    * (1, 2) community: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e742a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print standardized residuals for each pairwise comparison\n",
    "print(\"\\nStandardized Residuals for Each Pairwise Comparison:\")\n",
    "for pair, residuals_df in pairwise_residuals.items():\n",
    "    print(f\"\\nPair: {pair}\")\n",
    "    print(pd.DataFrame(residuals_df, index=contingency_table.index, columns=pair).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b9ee2",
   "metadata": {},
   "source": [
    "**Interpretation: Residuals**\n",
    "* Extreme Residuals: needs to be filled\n",
    "* Moderate Residuals: needs to be filled\n",
    "* Small Residuals: needs to be filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6238b",
   "metadata": {},
   "source": [
    "### 2.  Dataset: Create the tf-idf vector from the concatenated strings\n",
    "### * with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f800a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1903a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate the DataFrames\n",
    "def load_and_prepare_data(file_list):\n",
    "    dfs = [pd.read_json(file, orient='index') for file in file_list]\n",
    "    df = pd.concat(dfs, axis=1).fillna('')\n",
    "    df.columns = ['response1', 'response2', 'response3']\n",
    "    return df\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess(df):\n",
    "    return df.applymap(lambda x: ' '.join(simple_preprocess(str(x), deacc=True)))\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectors\n",
    "def create_tfidf_vectors(df):\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(df.values.flatten())\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    return tfidf_matrix, feature_names, vectorizer\n",
    "\n",
    "# Sum the vectors per document\n",
    "def sum_vectors_per_document(tfidf_matrix, df):\n",
    "    num_docs = df.shape[0]\n",
    "    summed_vectors = np.zeros((num_docs, tfidf_matrix.shape[1]))\n",
    "\n",
    "    for i in range(num_docs):\n",
    "        summed_vectors[i] = tfidf_matrix[i*df.shape[1]:(i+1)*df.shape[1]].sum(axis=0)\n",
    "\n",
    "    return summed_vectors\n",
    "\n",
    "# Convert summed vectors to Gensim corpus\n",
    "def convert_to_gensim_corpus(summed_vectors, feature_names):\n",
    "    dictionary = Dictionary([feature_names.tolist()])\n",
    "    corpus = []\n",
    "    for summed_vec in summed_vectors:\n",
    "        bow = [(i, summed_vec[i]) for i in range(len(summed_vec)) if summed_vec[i] > 0]\n",
    "        corpus.append(bow)\n",
    "    return corpus, dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c04ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "def train_lda(corpus, dictionary, num_topics=5, random_state=42):\n",
    "    lda_model = LdaMulticore(\n",
    "        corpus=corpus, \n",
    "        id2word=dictionary, \n",
    "        num_topics=num_topics, \n",
    "        passes=10, \n",
    "        workers=4, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    return lda_model\n",
    "\n",
    "# Compute coherence score\n",
    "def compute_coherence(lda_model, texts, dictionary):\n",
    "    cm = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    return cm.get_coherence()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2996bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File list\n",
    "files = [\n",
    "    '~/thesis/data/processed_uscensus/political_mention1.jsonl',\n",
    "    '~/thesis/data/processed_uscensus/political_mention2.jsonl',\n",
    "    '~/thesis/data/processed_uscensus/political_mention3.jsonl'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main process\n",
    "df = load_and_prepare_data(files)\n",
    "\n",
    "# Pre-process and tokenize data responses\n",
    "tokenized_responses = preprocess(df)\n",
    "responses_flat_tokenized = tokenized_responses.values.flatten().tolist()\n",
    "data_words = list(sent_to_words(responses_flat_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of words back into strings for TF-IDF vectorization\n",
    "merged_data_words_strings = [' '.join(words) for words in data_words]\n",
    "\n",
    "tfidf_matrix, feature_names, vectorizer = create_tfidf_vectors(tokenized_responses)\n",
    "summed_vectors = sum_vectors_per_document(tfidf_matrix, tokenized_responses)\n",
    "corpus, dictionary = convert_to_gensim_corpus(summed_vectors, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to determine the best number of topics\n",
    "num_topics_range = range(2, 11)  # Example range of topic numbers to try\n",
    "coherence_scores = []\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topics in num_topics_range:\n",
    "    lda_model = train_lda(corpus, dictionary, num_topics=num_topics, random_state=random_state)\n",
    "    coherence_lda = compute_coherence(lda_model, data_words, dictionary)\n",
    "    coherence_scores.append((num_topics, coherence_lda))\n",
    "    lda_model.save(f'lda_multicore_model_{num_topics}')  # Save model per topic number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de21874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print coherence scores for each number of topics\n",
    "for num_topics, coherence_lda in coherence_scores:\n",
    "    print(f'Num Topics: {num_topics}, Coherence Score: {coherence_lda}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a51e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best number of topics\n",
    "best_num_topics, best_coherence_lda = max(coherence_scores, key=lambda item: item[1])\n",
    "print(f'Best Num Topics: {best_num_topics}, Best Coherence Score: {best_coherence_lda}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc235e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the best model\n",
    "best_model_filepath = f'lda_multicore_model_{best_num_topics}'\n",
    "best_lda_model = LdaMulticore.load(best_model_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94601472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Visualize the LDA Model using PyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('/mnt/home/kim/thesis/lda-figure/anes/ldavis_participant_tfidf' + str(best_num_topics))\n",
    "\n",
    "# Prepare the visualization\n",
    "if not os.path.exists(LDAvis_data_filepath):\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(best_lda_model, corpus, dictionary)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "else:\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "# Save the visualization as an HTML file\n",
    "html_filepath = '/mnt/home/kim/thesis/lda-figure/anes/ldavis_participant_tfidf' + str(best_num_topics) + '.html'\n",
    "pyLDAvis.save_html(LDAvis_prepared, html_filepath)\n",
    "\n",
    "# Display the visualization inline (in Jupyter Notebook)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b9ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070bc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8b89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770364b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a714b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c67c194",
   "metadata": {},
   "source": [
    "## Linkage Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660a42c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data for the analysis - feature 1000 for each participant_id\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264ae55",
   "metadata": {},
   "source": [
    "### 1. Dimensionality reduction for the dendrogram(linkage matrix) visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fee61a",
   "metadata": {},
   "source": [
    "### PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "pca_result = pca.fit_transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e604c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = cosine_distances(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c765345",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix = sch.linkage(distance_matrix, method = 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Plot the Dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "sch.dendrogram(linkage_matrix, labels=final_df.index.tolist())\n",
    "plt.title('Dendrogram for PCA-Reduced Data')\n",
    "plt.xlabel('Documents')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d774c5",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e7757",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data type to compatible one to UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example of standardizing data\n",
    "scaler = StandardScaler()\n",
    "final_df_scaled = scaler.fit_transform(final_df)\n",
    "final_df_scaled = final_df_scaled.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbad3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize the umap model\n",
    "umap_model = umap.UMAP(n_components = 50, random_state = 42) \n",
    "umap_result = umap_model.fit_transform(final_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = cosine_distances(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix = sch.linkage(distance_matrix, method = 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fa2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Plot the Dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "sch.dendrogram(linkage_matrix, labels=final_df.index.tolist())\n",
    "plt.title('Dendrogram for PCA-Reduced Data')\n",
    "plt.xlabel('Documents')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64205b71",
   "metadata": {},
   "source": [
    "### 2. Heatmap instead of the Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to numpy array if needed\n",
    "if isinstance(final_df, pd.DataFrame):\n",
    "    final_df = final_df.values\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "final_df_scaled = scaler.fit_transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28abd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=5)  # Reduce to 50 components or adjust as needed\n",
    "pca_result = pca.fit_transform(final_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bde627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Distance Matrix\n",
    "distance_matrix = cosine_distances(pca_result)\n",
    "\n",
    "# Perform Hierarchical Clustering\n",
    "linkage_matrix = sch.linkage(distance_matrix, method='ward')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf28ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Cluster Dendrogram\n",
    "dendro = sch.dendrogram(linkage_matrix, no_plot=True)\n",
    "dendro_order = dendro['leaves']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the distance matrix\n",
    "distance_matrix_reordered = distance_matrix[np.ix_(dendro_order, dendro_order)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(distance_matrix_reordered, cmap='viridis', cbar=True, \n",
    "            xticklabels=np.array(dendro_order)+1, yticklabels=np.array(dendro_order)+1)\n",
    "plt.title('Heatmap of Clustering Distance Matrix (PCA)')\n",
    "plt.xlabel('Documents')\n",
    "plt.ylabel('Documents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b6f6d",
   "metadata": {},
   "source": [
    "### 2. Dataset: responses stacked\n",
    "### * with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaMulticore, CoherenceModel\n",
    "import pyLDAvis.gensim\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ea20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_json('~/thesis/data/processed_uscensus/political_mentions_stack.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# Set stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f757b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and remove stopwords\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c383ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['stack'].tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary and corpus\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "texts = data_words\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train LDA model and compute coherence score\n",
    "def train_and_compute_coherence(corpus, dictionary, texts, num_topics, random_state=0):\n",
    "    lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=num_topics, \n",
    "                             random_state=random_state, chunksize=100, passes=10, alpha=0.01, eta=0.9)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    return lda_model, coherence_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best number of topics\n",
    "num_topics_range = range(2, 11)\n",
    "coherence_scores = []\n",
    "random_state = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model saving path\n",
    "model_path_template = 'lda_multicore_model_{}.model'\n",
    "ldavis_path_template = '/mnt/home/kim/thesis/lda-figure/anes/ldavis_stack_{}.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8b3ed",
   "metadata": {},
   "source": [
    "## warning: don't run it, otherwise it will change the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topics in num_topics_range:\n",
    "    lda_model, coherence_score = train_and_compute_coherence(corpus, id2word, texts, num_topics, random_state)\n",
    "    lda_model.save(model_path_template.format(num_topics))  # Saving the model\n",
    "    coherence_scores.append((num_topics, coherence_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print coherence scores\n",
    "for num_topics, score in coherence_scores:\n",
    "    print(f'Num Topics: {num_topics}, Coherence Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best number of topics\n",
    "best_num_topics, best_coherence_score = max(coherence_scores, key=lambda item: item[1])\n",
    "print(f'Best Num Topics: {best_num_topics}, Best Coherence Score: {best_coherence_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3becb0",
   "metadata": {},
   "source": [
    "### reload the model that is saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c020fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the best model\n",
    "best_model_path = model_path_template.format(best_num_topics)\n",
    "lda_model = LdaMulticore.load(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28472fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize using PyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = ldavis_path_template.format(best_num_topics)\n",
    "\n",
    "if not os.path.exists(LDAvis_data_filepath):\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "else:\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "html_filepath = LDAvis_data_filepath.replace('.pkl', '.html')\n",
    "pyLDAvis.save_html(LDAvis_prepared, html_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf637fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the visualization inline\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f17468",
   "metadata": {},
   "source": [
    "### 3. Dataset: responses stacked\n",
    "### * with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c45f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759be8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_json('~/thesis/data/processed_uscensus/political_mentions_stack.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# Set stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and remove stopwords\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "data = data['stack'].tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tokenized words back into strings\n",
    "data_words_strings = [' '.join(words) for words in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Fit the vectorizer and transform the documents\n",
    "X_tfidf = vectorizer.fit_transform(data_words_strings)\n",
    "\n",
    "# Get the feature names (i.e., words) and create a mapping for Gensim\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "id2word = Dictionary([feature_names.tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8606d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the TF-IDF matrix to a Gensim-compatible corpus format\n",
    "corpus = []\n",
    "for doc in X_tfidf:\n",
    "    doc_tuples = list(enumerate(doc.toarray()[0]))\n",
    "    doc_tuples = [(i, val) for i, val in doc_tuples if val > 0]\n",
    "    corpus.append(doc_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e99a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first document's first 30 tokens\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train LDA model and compute coherence score\n",
    "def train_and_compute_coherence(corpus, dictionary, texts, num_topics, random_state=0):\n",
    "    lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=num_topics, \n",
    "                             random_state=random_state, chunksize=100, passes=10, alpha=0.01, eta=0.9)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    return lda_model, coherence_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best number of topics\n",
    "num_topics_range = range(2, 11)\n",
    "coherence_scores = []\n",
    "random_state = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375c29ac",
   "metadata": {},
   "source": [
    "### warning: don't run it, otherwise it will rewrite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the path and reload it later\n",
    "model_path_template = 'lda_multicore_model_{}.model'\n",
    "ldavis_path_template = '/mnt/home/kim/thesis/lda-figure/anes/ldavis_{}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topics in num_topics_range:\n",
    "    lda_model, coherence_score = train_and_compute_coherence(corpus, id2word, data_words, num_topics, random_state)\n",
    "    lda_model.save(model_path_template.format(num_topics))\n",
    "    coherence_scores.append((num_topics, coherence_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2574a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print coherence scores\n",
    "for num_topics, score in coherence_scores:\n",
    "    print(f'Num Topics: {num_topics}, Coherence Score: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a424362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best number of topics\n",
    "best_num_topics, best_coherence_score = max(coherence_scores, key=lambda item: item[1])\n",
    "print(f'Best Num Topics: {best_num_topics}, Best Coherence Score: {best_coherence_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c7445",
   "metadata": {},
   "source": [
    "### reload the LDA model from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56434d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the best model\n",
    "best_model_path = model_path_template.format(best_num_topics)\n",
    "lda_model = LdaMulticore.load(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize using PyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = ldavis_path_template.format(best_num_topics)\n",
    "\n",
    "if not os.path.exists(LDAvis_data_filepath):\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "else:\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "html_filepath = LDAvis_data_filepath.replace('.pkl', '.html')\n",
    "pyLDAvis.save_html(LDAvis_prepared, html_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bf269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the visualization inline\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecbf77",
   "metadata": {},
   "source": [
    "### 3. Dataset: responses stacked\n",
    "### * with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2607fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('~/thesis/data/processed_uscensus/political_mentions_stack.jsonl', orient='records', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e92726",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7accb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenising and removing the stopwords\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a40f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data['stack'].tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64db920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_words[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Flatten the tokenized words back into strings\n",
    "data_words_strings = [' '.join(words) for words in data_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed19594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Step 3: Fit the vectorizer and transform the documents\n",
    "X_tfidf = vectorizer.fit_transform(data_words_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Get the feature names (i.e., words) and create a mapping for Gensim\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "id2word = gensim.corpora.Dictionary([feature_names])\n",
    "\n",
    "# Step 5: Convert the TF-IDF matrix to a Gensim-compatible corpus format\n",
    "corpus = []\n",
    "for doc in X_tfidf:\n",
    "    doc_tuples = list(enumerate(doc.toarray()[0]))\n",
    "    doc_tuples = [(i, val) for i, val in doc_tuples if val > 0]\n",
    "    corpus.append(doc_tuples)\n",
    "\n",
    "# View the first document's first 30 tokens\n",
    "print(corpus[:1][0][:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build the LDA model using the TF-IDF-based corpus\n",
    "num_topics = 6  # number of topics based on the clustering result from the previous analysis\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       random_state=0,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       alpha=0.01,\n",
    "                                       eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2e523",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5dadb",
   "metadata": {},
   "source": [
    "### Visualize the result of topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304013d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('/mnt/home/kim/thesis/lda-figure/anes/ldavis_'+str(num_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09c97c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, '/mnt/home/kim/thesis/lda-figure/anes/ldavis_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65aac61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3342b03",
   "metadata": {},
   "source": [
    "## Additionally: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf5c4a",
   "metadata": {},
   "source": [
    "### Top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top words for each topic\n",
    "top_words_per_topic = []\n",
    "for t in range(num_topics):\n",
    "    top_words = [word for word, _ in lda_model.show_topic(t, topn=10)]\n",
    "    top_words_per_topic.append(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_per_topic[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2348af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute co-occurrence matrix\n",
    "def compute_cooccurrence_matrix(texts):\n",
    "    word_counts = Counter(word for text in texts for word in text)\n",
    "    total_count = sum(word_counts.values())\n",
    "    word_pairs = Counter()\n",
    "    for text in texts:\n",
    "        for i, j in combinations(set(text), 2):\n",
    "            word_pairs[tuple(sorted([i, j]))] += 1\n",
    "    return word_pairs, word_counts, total_count\n",
    "\n",
    "word_pairs, word_counts, total_count = compute_cooccurrence_matrix(data_words)\n",
    "\n",
    "# Compute NPMI\n",
    "def compute_npmi(word_pairs, word_counts, total_count):\n",
    "    npmi_matrix = {}\n",
    "    for (w_i, w_j), cooccur_count in word_pairs.items():\n",
    "        p_i = word_counts[w_i] / total_count\n",
    "        p_j = word_counts[w_j] / total_count\n",
    "        p_ij = cooccur_count / total_count\n",
    "        if p_ij > 0:\n",
    "            pmi = np.log(p_ij / (p_i * p_j))\n",
    "            npmi = pmi / -np.log(p_ij)\n",
    "            npmi_matrix[(w_i, w_j)] = npmi\n",
    "    return npmi_matrix\n",
    "\n",
    "npmi_matrix = compute_npmi(word_pairs, word_counts, total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f55b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average NPMI for each topic\n",
    "def average_npmi_for_topics(top_words_per_topic, npmi_matrix):\n",
    "    topic_npmis = []\n",
    "    for top_words in top_words_per_topic:\n",
    "        npmis = [npmi_matrix.get(tuple(sorted([w_i, w_j])), 0) for w_i, w_j in combinations(top_words, 2)]\n",
    "        if npmis:\n",
    "            topic_npmi = np.mean(npmis)\n",
    "            topic_npmis.append(topic_npmi)\n",
    "    return np.mean(topic_npmis) if topic_npmis else 0\n",
    "\n",
    "average_npmi = average_npmi_for_topics(top_words_per_topic, npmi_matrix)\n",
    "print(\"Average NPMI for LDA topics:\", average_npmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322a7ea",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "High NPMI (close to 1): Indicates strong semantic coherence between words, meaning the words are likely to appear together in similar contexts. This is generally considered good for topics generated by models like LDA.\n",
    "\n",
    "NPMI around 0: Indicates that the words appear together about as frequently as expected by chance, suggesting neutral association.\n",
    "\n",
    "Low NPMI (negative values): Indicates that the words are unlikely to appear together, suggesting poor coherence for the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186015b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
